# 多模态自回归大模型预训练（1B–30B）——公开教程（Index）

> **读者对象**：AI Scientist 与中型企业 Infra/平台工程师
> **交付物**：生产级的**多模态自回归 Transformer**（类 Qwen、早期融合、各模态离散化 token）**预训练 checkpoint** + 完整工程化流水线与文档
> **训练底座**：Megatron（Megatron-Core/Megatron-LM），**256×H100 80GB**，**一次训练以过完 10T token 为准**
> **数据侧目标**：自采/开源共 **100T token 池**（**中英 90%**、**其他语种 10%**；token 细分到具体数据集；数据治理为重中之重）

---

## 本书结构

> 本教程由 `index.md + chapter1.md + chapter2.md + ...` 组成。每章均提供工程化 checklist、脚本/代码、关键表格与可复现配置。建议按顺序阅读与实施。

1. **chapter1.md — 总览与技术路线**

   * 目标能力、范围边界、关键设计权衡（早期融合 vs. 后期融合、dense vs. MoE 等）
   * 统一 token 间与多模态对齐思想（离散化 + 位置/时间对齐）
   * 端到端系统图（数据→治理→离散化→混采→训练→评测→交付）

2. **chapter2.md — 项目管理与里程碑**

   * 贯穿 24–40 周的**总体时间线**（人员、风险、Go/No-Go 门槛）
   * 依赖矩阵（数据/算力/合规/监控）与灰度推进策略

3. **chapter3.md — 数据配方设计（100T token 池）**

   * 语言、模态与域的**目标配比**与**采样/退火**策略
   * **数据指标仪表盘**与“数据预算—token 化—训练吞吐”的对应关系

4. **chapter4.md — 文本数据：抓取、清洗、去重与质量分层**

   * 自研/复用开源清洗包（质量模型、毒性/PII/版权检测）
   * 高效去重（Exact + NearDup：MinHash/SimHash、跨模态近重）

5. **chapter5.md — 音频数据：合规抓取、ASR 对齐、RVQ 离散化**

   * CC 许可/自有授权的播客/演讲/采访；采样率、静音/噪声过滤
   * Encodec/音频 VQ-VAE + **多级 RVQ** 的离散化与码率控制

6. **chapter6.md — 视频数据：合规抓取、切片、时空离散化**

   * 短/长视频分路；镜头切分、OCR/字幕抽取与质量打分
   * 视频 VQ（帧-块/Tubelet）+ RVQ 的离散 token 生成与帧率策略

7. **chapter7.md — 图像数据：采集、质量打分与离散化**

   * ALT/TEXT 配对、审美/文本相关性打分
   * dVAE/VQGAN/VQ-VAE 离散化（典型 16×16 latent → 256 token/图）

8. **chapter8.md — Tokenizer 与词表：多模扩词、特殊符与对齐标注**

   * **文本沿用 Qwen tokenizer**，多模态扩展符（<img>, <aud>, <vid>, <seg>…）
   * 连续特征编码器后接 **RVQ**，统一成**离散 token**；时间/空间位置编码设计

9. **chapter9.md — 模型结构与超参数（1B/7B/14B/30B）**

   * 类 Qwen 的**dense Decoder-only** 架构、早期融合输入拼接
   * 长上下文（8k/16k）与 RoPE/旋转位置编码的多模态对齐

10. **chapter10.md — 训练基础施（Megatron @ 256×H100）**

    * 并行切分（TP/PP/DP/SP/CP）与推荐组合；ZeRO/Sharded Optimizer
    * Mixed Precision（BF16/FP8-TE）、FlashAttention、流水线调度与吞吐优化

11. **chapter11.md — 数据混采与课程策略**

    * 10T token 单轮训练的**模态/语言/域**采样曲线
    * 长序列 Packing、跨模态拼接、PAD/掩码规范

12. **chapter12.md — 监控与可观测性**

    * 训练/数据治理/离散化流水线的指标与报警；断点续训与灾备

13. **chapter13.md — 评测体系**

    * **Text/Audio/Video 的自回归 Perplexity**与**Vision-Language**指标（检索/描述/问答）
    * 评测集治理、泄漏检测、统计显著性与回归准则

14. **chapter14.md — 安全与合规**

    * 版权/许可、TOS/robots.txt、PII/敏感内容、地方法规
    * 红队与风险分级（数据→模型→发布）

15. **chapter15.md — 交付与落地**

    * Checkpoint/Tokenizer/离散器版本化与打包；推理样例与缩蒸馏路线

16. **appendixA.md — 计算与容量估算**（公式与算例）

17. **appendixB.md — 工具链与脚手架**（yt-dlp*/API、爬虫、ETL、Megatron 配置模板）

18. **appendixC.md — 常见故障与排障**

> * **重要合规提示**：仅抓取/下载**具备明确开放许可**的内容（例如 CC-BY/CC0 等），严格遵守各网站/平台的使用条款与 robots.txt；**切勿**绕过 DRM、付费墙或技术保护措施。本书仅提供合规的工程方法与模板，读者须自担合规审查责任。

---

## 一页式项目概览

### 模型与训练（单轮 10T token）

| 参数规模    | 推荐并行 (DP×TP×PP) |    上下文 | 优化器                |    估算训练时长* | 估算 GPU·Day* |
| ------- | --------------: | -----: | ------------------ | ---------: | ----------: |
| **1B**  |          64×2×2 |     8k | AdamW（BF16/FP8-TE） | **~7.7 天** |      ~1,975 |
| **7B**  |          16×8×2 | 8k/16k | 同上                 |  **~54 天** |     ~13,827 |
| **14B** |           8×8×4 | 8k/16k | 同上                 | **~108 天** |     ~27,654 |
| **30B** |          4×16×4 | 8k/16k | 同上                 | **~231 天** |     ~59,259 |

* 假设 256×H100 80GB、有效吞吐 ~**90 PFLOPS**（含通信/内存开销），训练 FLOPs 近似 **6×参数×token**。仅作预算与排期参考，实际取决于实现与利用率。

---

## 100T Token 数据池（自采 + 开源清洗包复用）

> **口径**：音频/视频/图像经编码器后**RVQ 离散化**为 token；图像 token 语言无关，**语言占比（中英 90%、其他 10%）按“有语义语言的 token”（文本+语音+视频）计算。**
> **10T 训练轮次**从该 100T 池**按配方采样**，并非一次性完整消耗。

### 1）模态级总览

| 模态     |   Token 预算 | 说明（离散化与规模）                                                       |
| ------ | ---------: | ---------------------------------------------------------------- |
| **文本** |  **94.0T** | Qwen tokenizer；多域/多语；高质量优先分层采样                                   |
| **音频** |   **2.5T** | 24 kHz；**8×RVQ**，约 **~400 token/s**；以 CC 语音/播客/演讲为主              |
| **视频** |   **2.5T** | 帧 latent（~**256 token/帧**）× **6 fps ≈ 1536 token/s**；教育/讲解/纪录片优先 |
| **图像** |   **1.0T** | dVAE/VQ-VAE，约 **256 token/图**；配对/无配对混合                           |
| **合计** | **100.0T** | 语言占比按“文本+音频+视频=99T”口径执行                                          |

**语言配比（面向 99T 语言相关 token）：**

* **中文 + 英文：90%（约 89.1T）** → 中文 ~40%、英文 ~50%（可微调为 45/45/10）
* **其他语种：10%（约 9.9T）** → 多语覆盖（西/法/德/葡/意/阿/印地/日/韩/俄…）

### 2）文本数据集细分（共 94.0T）

| 数据集（示例/来源类型）                         | 语言         | Token（T） | 说                           |
| ------------------------------------ | ---------- | -------: | ---------------------------- |
| **RefinedWeb-EN（自建 + 复用开源清洗包）**      | EN         | **34.5** | 通用英文网页（去重/质量打分/毒性与版权过滤）      |
| **RefinedWeb-ZH（自建 + 复用开源清洗包）**      | ZH         | **28.5** | 通用中文网页（含百科/社区长文/技术文档）        |
| **RefinedWeb-XX（多语，非中英）**            | 多语         |  **8.9** | CCNet/FineWeb/Dolma 等多语切片再治理 |
| **Wikipedia/Wikibooks/Wiktionary**   | EN/ZH/多语   |  **1.0** | 去重+结构化清洗；知识图谱字段剥离            |
| **Books（Gutenberg 等公共领域 + 合规中文书籍）**  | EN/ZH/少量多语 |  **2.5** | 章节/目录抽取；版权严格核验               |
| **ArXiv + PubMed 等开放论文/摘要**          | 以 EN 为主    |  **7.0** | 版式解析、公式处理、引用去噪               |
| **News（合源汇总）**                      | EN/ZH      |  **5.5** | 时效性分层；去聚合/去机器翻译痕迹            |
| **Q&A/论坛（StackExchange 等 + 合规中文社区）** | EN/ZH/多语   |  **4.0** | Markdown/代码块保留策略；毒性过滤        |
| **Gov/Legal（政府/司法/标准）**              | 多语         |  **2.1** | 许可与引用规范严格校验                  |
| **合计**                               |            | **94.0** |                              |

### 3）音频数据集细分（共 2.5T；约 400 token/s）

| 数据集（示例/来源类型）                                             | 语言       | Token（T） |      约合时长（小时）* | 说明                         |
| -------------------------------------------------------- | -------- | -------: | -------------: | -------------------------- |
| **CC 许可 YouTube 语音（讲座/播客/评测）**                           | EN/ZH/多语 |  **1.4** |       ~972,000 | API 合规索 + 频道白名单；静音/音乐占比过滤 |
| **开放播客/电台档案（CC/公有领域）**                                   | EN/ZH    |  **0.4** |       ~277,000 | 节目级元数据、章节/广告段识别            |
| **有标注通用语音（Common Voice/Libri 等）**                        | 多语       |  **0.1** |        ~69,000 | 口音覆盖、读法一致性治理               |
| **多语演讲/会议/公开课**                                          | 多语       |  **0.3** |       ~208,000 | 讲义/字幕对齐，建立说话人聚类            |
| **其他长语音资源（合规）**                                          | 多语       |  **0.3** |       ~208,000 | 长录音切片、VAD、去版权音乐            |
| **合计**                                                   |          |  **2.5** | **~1,734,000** |                            |
| * 近似换算：`时长(小时) ≈ Token(T) × 1e12 / (400 token/s) / 3600` |          |          |                |                            |

### 4）视频数据集细分（共 2.5T；约 1536 token/s）

| 数据集（示例/来源类型）                                              | 语言       | Token（T） |    约合时长（小时）* | 说明                      |
| --------------------------------------------------------- | -------- | -------: | -----------: | ----------------------- |
| **CC 许可 YouTube/教育视频**                                    | EN/ZH/多语 |  **1.5** |     ~271,000 | 讲解/纪录片/课堂优先；镜头切分与文字密度优先 |
| **教程/技术/科普短视频**                                           | EN/ZH    |  **0.4** |      ~72,000 | 竖屏适配；字幕/画面信息融合          |
| **纪录片/演讲剪辑**                                              | 多语       |  **0.3** |      ~54,000 | 主题/章节化索引                |
| **其他合规来源（机构公开素材等）**                                       | 多语       |  **0.3** |      ~54,000 | 版权条款核验                  |
| **合计**                                                    |          |  **2.5** | **~451,000** |                         |
| * 近似换算：`时长(小时) ≈ Token(T) × 1e12 / (1536 token/s) / 3600` |          |          |              |                         |

### 5）图像数据集细分（共 1.0T；约 256 token/图）

| 数据集（示例/来源类型）                             | Token（T） |   约合图片张数* | 说明                  |
| ---------------------------------------- | -------: | --------: | ------------------- |
| **大规模网页图像（ALT/TEXT 配对；LAION-like，自建管线）** |  **0.8** |     ~3.1B | 审美/相关性/NSFW/水印检测；去重 |
| **高质量图文对（教育/百科/技术插图等）**                  |  **0.2** |    ~0.78B | 图文一致性强，优先级权重更高      |
| **合计**                                   |  **1.0** | **~3.9B** |                     |
| * 近似换算：`张数 ≈ Token(T) × 1e12 / 256`      |          |           |                     |

---

## 10T 训练轮的默认采样配方（可在 chapter11 中按阶段调整）

| 模态     |     采样占比 | 对应 Token（T） |
| ------ | -------: | ----------: |
| 文本     |  **75%** |     **7.5** |
| 音频     |  **10%** |     **1.0** |
| 视频     |  **10%** |     **1.0** |
| 图像     |   **5%** |     **0.5** |
| **合计** | **100%** |    **10.0** |

**语言配比（针对 9.5T 语言相关 token：文本+音频+视频）**

* 中文：**~40%**（约 3.8T）
* 英文：**~50%**（约 4.75T）
* 其他语种：**~10%**（约 0.95T）

> **阶段建议**：Phase A（前 3T）文本偏重（85/7.5/5/2.5）；Phase B（中 4T）均衡（70/12/12/6）；Phase C（后 3T）多模偏重（60/20/15/5），并对视频/音频提高长样本权重。

---

## 整体时间线（示例，起算为第 0 周）

> 若目标 30B，**单轮 10T 训练周期约 7.5 个月**（含缓冲）；若 7B约 2 个月。可先以 **1B/7B 押注方案去风险**，再滚动放大到 14B/30B。

```
周 01–04  立项 & 里程碑定义；合规与风控 baseline；PoC 管线搭建
周 03–10  文本/图像/音频/视频数据抓取 & 初步治理（并行）；质量模型上线
周 06–12  离散化器（音频/视频/图像）训练与 RVQ 定格；统一 tokenizer 定版
周 08–12  1B 小模型预训练（10T×试训 1–2T）→ 指标线对齐 → Go/No-Go
周 10–15  7B 规模化预训练（目标过完 10T）；评测与回归
周 14–22  14B/30B 准备（并行）：并行度/批量/IO 优化；数据二次治理
周 16–34  30B 预训练（10T）主线；中期/末期评测与回归；故障演练
周 35–38  模型冻结/验收；checkpoint/离散器/词表打包；发布与归档
```

**关键 Go/No-Go 门槛（示例）**

* 数据：重复率 < 3%，PII/受限内容召回 > 95%，多语覆盖度 ≥ 10 种主语种
* 训练：吞吐利用率 ≥ 32%，稳定无 NaN ≥ 1e6 step，显存值与通信抖动达标
* 评测：Text/Audio/Video ppl 边际下降曲线健康；V-L 任务达到预设阈值

---

## 评测总览（细节见 chapter13）

* **自回归 Perplexity（ppl）**：

  * 文本：多域/多语（新闻/百科/代码注释/论坛）
  * 音频：语音 token 流 ppl（分语种/口音/噪声场景）
  * 视频：视频 token 流 ppl（分类目：教育/纪录片/短视频）
* **Vision-Language**（统一自回归头，早期融合）：

  * 图文检索（R@k）、图文描述（CIDEr/BLEU/CLIPScore）、图文问答（针对多样视觉语义）
* **数据泄漏与重叠检测**：训练/评测交叉去重、最近邻相似性阈值
* **统计与置信**：bootstrap、分布漂移检测、回归测试基线

---

## 工程与合规要点（全书贯穿）

* **合法来源 + 许可清晰**：只使用 CC/公有领域/自有授权内容；严格遵守网站 TOS 与 robots.txt；不绕过 DRM/付费墙/技术限制。
* **PII/敏感内容治理**：正则 + NER + 小型分类器 + 启发式 + 人审抽检。
* **跨模态近重去重**：文本 embedding + 感知 hash（图像/视频缩略帧）+ 语音指纹。
* **偏见与安全**：毒性/仇恨/成人/暴力分级；多语安全分类器；红队脚本。
* **可审计与可追溯**：每条数据的 lineage/哈希/许可记录；不可变元数据仓。

---

## 你将得到什么（交付物）

* **预训练 checkpoint**（1B/7B/14B/30B 任一或多档）
* **统一 tokenizer 与多模态离散化器**（版本与码率固定）
* **Megatron 训练与评测配置**（TP/PP/DP、混采策略、profile 报告）
* **数据治理与采样配置**（可复现实验编号、过滤器权重、质量阈值）
* **评测报告**（ppl 与 V-L 指标、泄漏检查、误差分析）

---

## 如何使用本教程

1. **先跑通 PoC**（chapter1–3、8、10、11 的最小路径）。
2. **从 1B/7B 起步**，建立 ppl 与 V-L 的“可预期”下降曲线与数据质量仪表盘。
3. **滚动治理与扩容**：据—训练—评测三线并行，达标后放大到 14B/30B。
4. **严格合规**：每次引入新数据源都通过 chapter14 的 checklist。
5. **版本化一切**：数据切片、过滤器、离散化器、词表、训练配置、评测集。

---

## 术语与约定

* **Token**：文本 BPE token 或经编码器+RVQ 得到的离散 token。
* **10T 训练轮**：从 100T 数据池按设定配方采样 10T token 进行一次完整训练。
* **ppl**：自回归负对数似然的困惑度。
* **RVQ**：Residual Vector Quantization。
* **TP/PP/DP/SP/CP**：Megatron 的张量/流水/数据/序列/上下文并行。
