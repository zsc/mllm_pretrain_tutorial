<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第 6 章 — 视频数据：合规抓取、切片与时空离散化</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">index.md（导读与目录）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 1: 总览与技术路线</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">项目管理与里程碑</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第三章：数据配方设计（100T token 池）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 4 章 文本数据：抓取、清洗、去重与质量分层</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 5 章 — 音频数据：合规抓取、ASR 对齐、RVQ 离散化</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 6 章 — 视频数据：合规抓取、切片与时空离散化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 7 章 — 图像数据：采集、质量打分与离散化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Tokenizer 与词表：多模扩词、特殊符与对齐</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">模型结构与超参数（1B/10B）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十章：训练基础设施（Megatron @ 256×H100）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 11 章：数据混采与课程策略（10T token 单轮）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十二章：监控与可观测性</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十三章 评测体系：从自回归困惑度到视觉语言指标</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十四章：安全与合规</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十五章：交付与落地（Checkpoint & 蒸馏）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="appendixA.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">附录 A：计算与容量估算（公式与算例）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="appendixB.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">附录 B：工具链与脚手架（配置与模板）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="6">第 6 章 — 视频数据：合规抓取、切片与时空离散化</h1>
<h2 id="61">6.1 开篇与学习目标</h2>
<p>视频是信息密度最高、也最具挑战性的模态。它融合了时序变化的视觉信息、同步的音频流以及潜在的文本内容（字幕、场景文字）。处理视频数据的复杂性不仅在于其巨大的存储和计算开销，更在于如何将其有效地转化为模型可以理解的、统一的离散符号序列。本章将全面拆解构建大规模视频预训练数据集的完整流程，从数据源的合规获取，到时空维度的智能采样，再到最终转换为离散 token 的核心技术。</p>
<p><strong>学习目标:</strong></p>
<ul>
<li>掌握视频数据的主流来源、合规抓取方法与元数据的重要性。</li>
<li>理解视频时空采样策略（镜头切分、关键帧、Tubelet）的原理与权衡。</li>
<li>学会从视频中抽取并对齐多模态信息（音轨、字幕、OCR）。</li>
<li>深入理解视频离散化技术，特别是基于 VQ-VAE 和 RVQ 的时空 token 化方案。</li>
<li>建立视频数据处理的成本模型，并学会设计高效的存储与搬运策略。</li>
</ul>
<h2 id="62-youtubecc">6.2 来源与许可（YouTube/学术/CC 库），字幕/元数据抓取</h2>
<p>与文本和图像相比，高质量、大规模且拥有清晰许可的视频数据更为稀缺。因此，数据源的选择和合规性审查是整个项目的第一道防线。</p>
<ul>
<li>
<p><strong>主要来源</strong>:</p>
<ol>
<li><strong>YouTube</strong>: 最大的用户生成内容视频库，内容覆盖极其广泛。但许可复杂，需严格遵守其服务条款（TOS）和 <code>robots.txt</code> 规则。抓取时应优先选择带有知识共享（Creative Commons, CC）许可的频道和视频。</li>
<li><strong>学术数据集</strong>: 例如 HowTo100M、Something-Something V2、WebVid 等，这些数据集通常经过初步清洗，有明确的研究用途许可，是构建高质量训练集的绝佳起点。</li>
<li><strong>专业视频库</strong>: 如 Vimeo、Pexels 等，其中包含大量高质量、CC 许可的素材，适合用于补充特定领域（如自然风光、艺术创作）。</li>
</ol>
</li>
<li>
<p><strong>抓取工具与策略</strong>:</p>
<ul>
<li><code>yt-dlp</code> 是抓取 YouTube 视频的事实标准工具。务必配置其以下载所有可用资源：最高分辨率的视频、所有语言的音轨、所有格式的字幕（自动生成和手动上传）、以及视频的元数据（标题、描述、标签、上传者信息）。</li>
<li>对于受 API 保护的学术库，应使用官方提供的下载脚本，并注意遵循其速率限制。</li>
</ul>
</li>
<li>
<p><strong>元数据的重要性</strong>:
    视频的标题、描述和用户标签是极其宝贵的弱监督信号。这些文本信息可以用来：</p>
<ul>
<li>初步过滤内容（例如，搜索包含“教程”、“演讲”等关键词的视频）。</li>
<li>与视频内容进行语义对齐，作为 CLIP 式对比学习的原始文本对。</li>
<li>辅助生成视频的文本描述。</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>经验法则 (Rule-of-Thumb)</strong>
永远优先抓取并存储所有可用的元数据和多语言字幕。手动上传的字幕质量远高于自动生成的字幕，应给予更高权重。即使是低质量的 ASR 字幕，也比没有文本信息要好。一个视频文件的价值，很大程度上取决于其附带的元数据质量。</p>
</blockquote>
<h2 id="63-fpstubelet">6.3 镜头切分与采样（fps、关键帧、Tubelet）</h2>
<p>原始视频流在时间和空间上都存在大量冗余。直接处理完整视频不仅计算成本高昂，也可能稀释有效信息。因此，必须进行智能的切分与采样。</p>
<ul>
<li>
<p><strong>镜头切分 (Shot Detection)</strong>: 一个视频通常由多个镜头组成。在镜头切换点进行切分，可以得到语义上连贯的视频片段。这远优于按固定时长（如每10秒）切分的“硬切”方法。</p>
<ul>
<li><strong>工具</strong>: 可以使用 <code>PySceneDetect</code> 或基于深度学习的镜头检测模型。</li>
<li><strong>目标</strong>: 将长视频分解为一系列时长在 3-15 秒的语义单元（shots）。</li>
</ul>
</li>
<li>
<p><strong>帧采样率 (Frames Per Second, FPS)</strong>: 原始视频的 FPS（通常为 24/30/60）对于模型来说过高。需要进行降采样。</p>
<ul>
<li><strong>策略</strong>: 对于内容变化缓慢的视频（如演讲、教学），1-2 FPS 可能就足够了。对于动作密集型视频（如体育、舞蹈），可能需要 4-8 FPS。</li>
<li><strong>权衡</strong>: 更高的 FPS 能更好地捕捉动态信息，但会线性增加 token 数量和计算成本。一个常见的折中是全局采用 3-4 FPS。</li>
</ul>
</li>
<li>
<p><strong>Tubelet 采样</strong>: 这是将视频片段输入到视觉编码器的标准方式。一个 Tubelet 是一个时空“立方块”，例如 <code>16帧 x 224x224像素</code>。</p>
<ul>
<li><strong>流程</strong>: 从一个镜头片段中，以一定的步长（stride）采样一系列 Tubelet。如果片段长度不足一个 Tubelet，可以进行填充（padding）或舍弃。</li>
</ul>
</li>
</ul>
<p>下面的 ASCII 图展示了从视频到 Tubelet 的过程：</p>
<div class="codehilite"><pre><span></span><code><span class="err">原始视频</span><span class="w"> </span><span class="p">(</span><span class="mf">30f</span><span class="n">ps</span><span class="p">)</span>
<span class="w">  </span><span class="o">|</span>
<span class="w">  </span><span class="o">+--</span><span class="w"> </span><span class="p">[</span><span class="err">镜头切分</span><span class="p">]</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="err">镜头</span><span class="mi">1</span><span class="w"> </span><span class="p">(</span><span class="err">长度</span><span class="o">:</span><span class="w"> </span><span class="mi">8</span><span class="err">秒</span><span class="p">)</span>
<span class="w">                          </span><span class="o">|</span>
<span class="w">                          </span><span class="o">+--</span><span class="w"> </span><span class="p">[</span><span class="err">降采样</span><span class="w"> </span><span class="err">@</span><span class="w"> </span><span class="mf">4f</span><span class="n">ps</span><span class="p">]</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="err">帧</span>
<span class="w">                                                  </span><span class="o">|</span>
<span class="w">                                                  </span><span class="o">+--</span><span class="w"> </span><span class="p">[</span><span class="n">Tubelet</span><span class="w"> </span><span class="err">采样</span><span class="p">]</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">Tubelet</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="p">(</span><span class="err">帧</span><span class="w"> </span><span class="mi">1</span><span class="o">-</span><span class="mi">16</span><span class="p">)</span>
<span class="w">                                                  </span><span class="o">|</span>
<span class="w">                                                  </span><span class="o">+--</span><span class="w"> </span><span class="p">[</span><span class="n">Tubelet</span><span class="w"> </span><span class="err">采样</span><span class="p">]</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">Tubelet</span><span class="w"> </span><span class="n">B</span><span class="w"> </span><span class="p">(</span><span class="err">帧</span><span class="w"> </span><span class="mi">17</span><span class="o">-</span><span class="mi">32</span><span class="p">)</span>
</code></pre></div>

<h2 id="64-ocr">6.4 音轨/字幕抽取、OCR 与语义对齐</h2>
<p>视频的价值在于其多模态的内在对齐。必须将这些伴生信息完整地抽取出来，并保留其时序关系。</p>
<ul>
<li><strong>音轨抽取</strong>: 使用 <code>ffmpeg</code> 等工具可以无损地从视频容器中分离出音频流。<code>ffmpeg -i video.mp4 -vn -acodec copy audio.aac</code>。该音频流将进入第 5 章描述的音频处理流水线。</li>
<li><strong>字幕对齐</strong>: 字幕文件（如 <code>.srt</code>）天然包含了文本与时间戳。这是最强的监督信号之一，必须精确地将每个字幕片段与对应的视频帧和音频片段对齐。</li>
<li><strong>场景文字识别 (OCR)</strong>: 视频画面中常常包含重要的文本信息，如演示文稿的标题、路标、产品标签等。以对关键帧定期运行 OCR 模型（如 PaddleOCR、EasyOCR）来提取这些文字。提取出的文字及其出现的时间范围（帧号）也应被记录下来。</li>
</ul>
<p>所有抽取出的信息（音频片段、字幕、OCR 文本）都必须与视频帧的时间戳严格对齐，形成一个统一的多模态时间轴。</p>
<h2 id="65-vq-rvqtoken">6.5 离散化：视频 VQ + RVQ（帧块码本、token/秒）</h2>
<p>这是将连续的视频信号转换为离散 token 序列的核心步骤，其目标是将一个 Tubelet 压缩成一小组离散的 ID。</p>
<ul>
<li>
<p><strong>整体架构</strong>:</p>
<ol>
<li><strong>视频编码器 (Encoder)</strong>: 一个 3D 卷积网络（如 3D ResNet）或时空 Transformer（如 ViViT），接收一个 Tubelet 作为输入，输出一个低维度的时空特征图（latent feature map）。例如，一个 <code>16x224x224</code> 的 Tubelet 可能被编码为 <code>8x14x14</code> 的特征图。</li>
<li><strong>量化器 (Quantizer)</strong>: 对特征图中的每一个特征向量，使用 <strong>残差向量量化 (Residual Vector Quantization, RVQ)</strong> 将其映为一组离散的码本索引（codebook indices）。</li>
</ol>
</li>
<li>
<p><strong>为何使用 RVQ</strong>:
    相比于标准的 VQ-VAE，RVQ 使用多个级联的、较小的码本。第一级 VQ 对原始向量进行量化，然后后续的 VQ 对前一级的量化残差进行量化。</p>
<ul>
<li><strong>优势</strong>: 可以在码本大小（词表）可控的前提下，实现更高精度的表示。例如，使用 4 个大小为 1024 的码本（<code>4 x 1024</code>），可以组合出 <code>1024^4</code> 种可能的表示，远超单个大码本。这对于细节丰富的视频至关重要。</li>
</ul>
</li>
<li>
<p><strong>Token 速率计算</strong>:
    假设：</p>
<ul>
<li>视频采样率为 4 FPS。</li>
<li>Tubelet 包含 16 帧（即 4 秒内容）。</li>
<li>编码器输出 <code>t * h * w</code> = <code>8 * 14 * 14</code> 的时空特征。</li>
<li>RVQ 使用 4 个码本。</li>
<li>每个特征向量被量化为 4 个 token。</li>
</ul>
<p>总 token 数 = <code>8 * 14 * 14 * 4 = 6272</code> tokens
视频时长 = <code>16 帧 / 4 FPS = 4</code> 秒
<strong>Token 速率</strong> = <code>6272 tokens / 4 秒 = 1568</code> tokens/秒</p>
</li>
</ul>
<p>这个速率是设计模型上下文长度、计算资源规划和数据预算的基石。</p>
<div class="codehilite"><pre><span></span><code><span class="n">Tubelet</span><span class="w"> </span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="w"> </span><span class="n">H</span><span class="p">,</span><span class="w"> </span><span class="n">W</span><span class="p">,</span><span class="w"> </span><span class="n">C</span><span class="p">)</span>
<span class="w">     </span><span class="o">|</span>
<span class="w">     </span><span class="n">v</span>
<span class="mi">3</span><span class="n">D</span><span class="w"> </span><span class="n">ConvNet</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">ViT</span><span class="w"> </span><span class="n">Encoder</span>
<span class="w">     </span><span class="o">|</span>
<span class="w">     </span><span class="n">v</span>
<span class="n">Latent</span><span class="w"> </span><span class="n">Feature</span><span class="w"> </span><span class="nf">Map</span><span class="w"> </span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="n">h</span><span class="p">,</span><span class="w"> </span><span class="n">w</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="p">)</span>
<span class="w">     </span><span class="o">|</span>
<span class="w">     </span><span class="n">v</span>
<span class="o">+-----------------------------+</span>
<span class="o">|</span><span class="w">    </span><span class="n">Residual</span><span class="w"> </span><span class="n">Vector</span><span class="w">          </span><span class="o">|</span>
<span class="o">|</span><span class="w">    </span><span class="n">Quantization</span><span class="w"> </span><span class="p">(</span><span class="n">RVQ</span><span class="p">)</span><span class="w">       </span><span class="o">|</span>

<span class="o">|</span><span class="w">    </span><span class="n">Quantization</span><span class="w"> </span><span class="p">(</span><span class="n">RVQ</span><span class="p">)</span><span class="w">       </span><span class="o">|</span>
<span class="o">|</span><span class="w">                             </span><span class="o">|</span>
<span class="o">|</span><span class="w">  </span><span class="n">Codebook</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">Token_1</span><span class="w">      </span><span class="o">|</span>
<span class="o">|</span><span class="w">  </span><span class="n">Residual_1</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">Codebook</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">Token_2</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w">  </span><span class="n">Residual_2</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p">...</span><span class="w">          </span><span class="o">|</span>

<span class="o">+-----------------------------+</span>
<span class="w">     </span><span class="o">|</span>
<span class="w">     </span><span class="n">v</span>
<span class="n">Discrete</span><span class="w"> </span><span class="kt">Token</span><span class="w"> </span><span class="n">Sequence</span><span class="w"> </span><span class="p">(</span><span class="n">N_tokens</span><span class="p">)</span>
</code></pre></div>

<h2 id="66">6.6 质量过滤</h2>
<p>原始视频数据质量参差不齐，必须进行严格的自动化过滤。</p>
<ul>
<li><strong>模糊/低分辨率</strong>: 使用拉普拉斯算子方差（Laplacian variance）等方法评估帧的清晰度，过滤掉模糊的片段。</li>
<li><strong>水印/台标</strong>: 训练一个专门的 logo/水印检测器，或者使用模板匹配方法，过滤掉带有大量商业水印的视频。</li>
<li><strong>重复内容</strong>: 对关键帧提取感知哈希（如 pHash, dHash）或 CLIP 特征向量，检测并除高度相似或完全重复的视频片段。</li>
<li><strong>无关内容</strong>: 使用一个预训练的视频/图像分类模型（如 CLIP），过滤掉不希望出现的内容，例如静态的“即将开始”画面、视频末尾的订阅推广、纯广告片段等。</li>
</ul>
<h2 id="67-tb">6.7 存储与搬运成本模型（TB/小时、分层存储、预取）</h2>
<p>视频数据是存储和带宽的“吞噬巨兽”，必须精打细算。</p>
<ul>
<li>
<p><strong>成本模型</strong>:
    一个粗略的成本模型可以表示为：
    <code>总成本 = 存储成本 + 计算成本 + 网络成本</code>
    <code>存储成本 = (原始数据 TB * 冷存单价) + (中间/离散化数据 TB * 热存单价)</code>
    <code>网络成本 = 数据搬运 TB * 带宽单价</code></p>
</li>
<li>
<p><strong>分层存储策略</strong>:</p>
<ol>
<li><strong>冷存储 (Cold Storage)</strong>: 如 AWS S3 Glacier Deep Archive。用于存放抓取下来的原始视频文件。成本极低，但访问延迟高。</li>
<li><strong>热存储 (Hot Storage)</strong>: 如高性能对象存储或并行文件系统（Lustre, GPFS）。用于存放已经切片、离散化为 token 的数据。这些数据需要被训练集群高速、低延迟地访问。</li>
</ol>
</li>
<li>
<p><strong>数据搬运与预取</strong>:
    数据处理流水线（ETL）应部署在离冷存储近的计算资源上，将处理后的 tokenized 数据推送到离 H100 集群近的热存储上。训练时，数据加载器（data loader）必须实现高效的<strong>预取（prefetching）</strong>机制，确保在一个 mini-batch 的计算完成前，下一个 batch 的数据已经从存储拉取到 GPU 内存中，避免 GPU 因等待 I/O 而空闲。</p>
</li>
</ul>
<blockquote>
<p><strong>经验法则 (Rule-of-Thumb)</strong>
假设一个 256xH100 集群的训练吞吐量为 20k tokens/秒/GPU，总吞吐量约为 5.12M tokens/秒。如果视频 token 速率为 1.5k tokens/秒，则集群每秒消耗约 3400 秒时长的视频数据。数据预处理和加载流水线的吞吐能力必须至少是这个数字的 1.2 倍，才能保证不成为瓶颈。</p>
</blockquote>
<h2 id="68">6.8 合成视频与数据扩增（可选）</h2>
<p>在特定领域数据不足时，可以考虑使用合成数据。</p>
<ul>
<li><strong>合成视频</strong>: 使用先进的文本到视频生成模型（如 Sora 的小型开源替代品），根据特定文本提示生成视频，用于补足长尾分布中的场景。例如，生成“宇航员在火星上弹吉他”的视频。这需要极高的计算成本，通常只用于小规模的精确补足。</li>
<li><strong>数据扩增</strong>: 在将 Tubelet 送入编码器之前，可以应用标准的视觉数据扩增技术，如随机水平翻转、颜色抖动、随机裁切等。这可以有效增加数据多样性，提高模型泛化能力。</li>
</ul>
<h2 id="69-token">6.9 Token 预算与课程调度</h2>
<p>视频数据在整个 30T token 的总预算中应占有合理比例。其高信息密度和高 token 速率意味着它会快速消耗 token 预算。</p>
<ul>
<li><strong>Token 预算</strong>: 假设视频数据占总 token 预算的 10-20%（即 3T - 6T tokens）。根据之前计算的 1.5k tokens/秒速率，这对应着约 55万 - 110万 小时的视频内容。这是一个巨大的数据工程挑战。</li>
<li><strong>课程调度 (Curriculum Learning)</strong>: 建议采用分阶段的策略：<ol>
<li><strong>阶段一</strong>: 优先使用高质量、短小（5-30秒）、与文本描述强相关的视频（如教学片段、产品评测）。这有助于模型在早期稳定地学习跨模态关联。</li>
<li><strong>阶段二</strong>: 逐渐引入更长、更复杂、文本监督信号更弱的视频（如电影、纪录片），并相应增加模型的上下文长度。</li>
</ol>
</li>
</ul>
<h2 id="610">6.10 本章小结</h2>
<p>本章详细阐述了将原始视频转化为模型可用的离散 token 序列的全过程。我们从合规的数据源选择和元数据抓取开始，强调了其对项目成功的基础性作用。接着，我们讨论了如何通过镜头切分和 Tubelet 采样来处理视频的时空冗余。核心技术部分深入解析了基于 VQ-VAE 和 RVQ 的视频离散化方案，并给出了 token 速率的估算方法。最后，我们覆盖了质量过滤、存储成本管理和课程学习等关键工程实践。成功处理好视频数据，是构建真正强大的多模态模型的关键一步，它本质上是一个大规模的分布式数据物流与计算问题。</p>
<h2 id="611-gotchas">6.11 常见陷阱与错误（Gotchas）</h2>
<ol>
<li><strong>忽略许可证与服务条款</strong>: 直接抓取大量受版权保护的视频内容可能导致严重的法律风险，甚至项目中止。务必建立严格的合规审查流程。</li>
<li><strong>时间戳错位</strong>: 在抽取音轨、字幕、OCR 时，如果时间戳未能精确对齐，模型将学到错误的跨模态关联（例如，声音与口型不匹配）。必须使用统一的时钟基准，并进行严格的同步校验。</li>
<li><strong>存储 I/O 瓶颈</strong>: 低估了训练集群对数据加载的吞吐量需求。在热存储选型和数据加载器设计上投入不足，会导致昂贵的 GPU 资源大量时间在等待数据。</li>
<li><strong>“一刀切”的采样率</strong>: 对所有类型的视频使用相同的 FPS 进行降采样。这可能导致在动作密集视频中丢失关键动态信息，或在静态视频中浪费存储和计算。应考虑基于内容动态性自适应采样策略。</li>
<li><strong>RVQ 码本崩溃 (Codebook Collapse)</strong>: 在训练视频 VQ-VAE 时，如果超参数或初始化不当，可能导致码本中的大量 code 从未被使用，从而降低表示能力。需要仔细监控码本利用率，并使用码本重置等技巧。</li>
<li><strong>元数据丢失</strong>: 在多步 ETL 流程中，原始视频的标题、描述等宝贵元数据意外丢失，使得后续无法利用这些弱监督信号。数据处理的每一步都应确保元数据的完整传递。</li>
<li><strong>视频质量评估不足</strong>: 未能有效过滤掉低质量（模糊、严重压缩、带巨大水印）的视频，导致模型在“脏”数据上浪费了大量的计算资源，并可能学习到噪声模式。</li>
</ol>
            </article>
            
            <nav class="page-nav"><a href="chapter5.html" class="nav-link prev">← 第 5 章 — 音频数据：合规抓取、ASR 对齐、RVQ 离散化</a><a href="chapter7.html" class="nav-link next">第 7 章 — 图像数据：采集、质量打分与离散化 →</a></nav>
        </main>
    </div>
</body>
</html>