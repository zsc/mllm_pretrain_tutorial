<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第三章：数据配方设计（100T token 池）</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">index.md（导读与目录）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 1: 总览与技术路线</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">项目管理与里程碑</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第三章：数据配方设计（100T token 池）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 4 章 文本数据：抓取、清洗、去重与质量分层</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 5 章 — 音频数据：合规抓取、ASR 对齐、RVQ 离散化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 6 章 — 视频数据：合规抓取、切片与时空离散化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 7 章 — 图像数据：采集、质量打分与离散化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Tokenizer 与词表：多模扩词、特殊符与对齐</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">模型结构与超参数（1B/10B）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十章：训练基础设施（Megatron @ 256×H100）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 11 章：数据混采与课程策略（10T token 单轮）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十二章：监控与可观测性</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十三章 评测体系：从自回归困惑度到视觉语言指标</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十四章：安全与合规</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十五章：交付与落地（Checkpoint & 蒸馏）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="appendixA.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">附录 A：计算与容量估算（公式与算例）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="appendixB.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">附录 B：工具链与脚手架（配置与模板）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="appendixC.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">附录 C — 常见故障与排障（Runbook）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="100t-token">第三章：数据配方设计（100T token 池）</h1>
<h2 id="31">3.1 开篇与学习目标</h2>
<p>如果说模型架构是引擎，算力是燃料，那么数据就是决定这台引擎最终能驶向何方的蓝图与导航系统。一个精心设计的数据配方（Data Recipe）是大规模预训练成功的基石，其重要性不亚于模型结构本身。本章将深入探讨如何从零开始，设计一个规模宏大（目标构建一个 100 万亿 Token 的数据池）、模态丰富、质量可控的数据配方。</p>
<p><strong>学习目标:</strong></p>
<ul>
<li>理解多模态数据配方的核心设计原则：平衡性、多样性、高质量。</li>
<li>掌握将宏观 Token 预算分解到具体模态、语言、领域和数据集的方法。</li>
<li>学会设计数据质量分层与动态采样策略（课程学习与退火）。</li>
<li>明晰开源、自采与合成数据在配方中的战定位与组合方式。</li>
<li>建立数据版本化与数据卡（Data Card）的最佳实践。</li>
</ul>
<h2 id="32">3.2 模态/语言/域目标配比</h2>
<p>数据配方的第一步是确立高层目标。这直接决定了模型最终的能力倾向。我们的目标是构建一个生成与理解一体化的多模态模型，因此配比需要兼顾文本的核心推理能力与其他模态的感知与生成能力。</p>
<p><strong>核心原则：</strong> 模型的最终能力是训练数据分布的直接反映。</p>
<h4 id="_1">语言配比</h4>
<p>根据项目目标，我们设定以下语言分布，旨在打造一个以中英文为核心，兼具多语言能力的模型：</p>
<ul>
<li><strong>中文/英文：~90%</strong>。这是模型核心语言能力的基础。英文语料质量高、数量大，是推理和编码能力的基石。中文语料是项目的核心差异化优势。两者比例可根据具体应用场景微调，例如 50% 英文，40% 中文。</li>
<li><strong>其他主要语种：~10%</strong>。包括但不限于代码（作为一种特殊语言）、日语、韩语、德、法语、西班牙语等。这部分数据用于提升模型的跨语言泛化能力和代码能力。</li>
</ul>
<h4 id="_2">模态配比</h4>
<p>这是一个经验与目标驱动的决策。由于文本是信息密度最高、知识体系最完备的模态，我们以文本为主，其他模态为辅。</p>
<p><strong>经验法则 (Rule-of-Thumb):</strong>
在总 Token 预算中，文本应占据主导地位（&gt;60%），因为它承载了最多的抽象知识、逻辑和推理。视频数据由于同时包含视觉和音频信息，且时序信息丰富，其 Token 预算应相对较高。</p>
<p>一个建议的 <strong>100T Token 数据池</strong> 目标配比表格如下：</p>
<p>| 模态 (Modality) | 目标 Token 比例 | 目标 Token 数量 (万亿) | 核心能力构建 | 备注 |</p>
<table>
<thead>
<tr>
<th style="text-align: left;">模态 (Modality)</th>
<th style="text-align: left;">目标 Token 比例</th>
<th style="text-align: left;">目标 Token 数量 (万亿)</th>
<th style="text-align: left;">核心能力构建</th>
<th style="text-align: left;">备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>文本 (Text)</strong></td>
<td style="text-align: left;">65%</td>
<td style="text-align: left;">65</td>
<td style="text-align: left;">知识、推理、语言、代码</td>
<td style="text-align: left;">模型能力的地基</td>
</tr>
<tr>
<td style="text-align: left;"><strong>图像 (Image)</strong></td>
<td style="text-align: left;">10%</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">视觉理解、图文对齐</td>
<td style="text-align: left;">通常与文本交错出现</td>
</tr>
<tr>
<td style="text-align: left;"><strong>音频 (Audio)</strong></td>
<td style="text-align: left;">10%</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">语音识别、声纹、音、声效</td>
<td style="text-align: left;">ASR 转写文本不计入此</td>
</tr>
<tr>
<td style="text-align: left;"><strong>视频 (Video)</strong></td>
<td style="text-align: left;">15%</td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">时空理解、动态事件、音视频对齐</td>
<td style="text-align: left;">Token 成本最高</td>
</tr>
<tr>
<td style="text-align: left;"><strong>总计</strong></td>
<td style="text-align: left;"><strong>100%</strong></td>
<td style="text-align: left;"><strong>100</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<h4 id="_3">领域配比</h4>
<p>在各模态内部，还需进一步细分领域，以确保模型的多样性。以 65T 文本 Token 为例：</p>
<p>| 文本领域 (Domain) | 建议比例 | 核心价值 |</p>
<table>
<thead>
<tr>
<th style="text-align: left;">文本领域 (Domain)</th>
<th style="text-align: left;">建议比例</th>
<th style="text-align: left;">核心价值</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">通用网页 (Web)</td>
<td style="text-align: left;">40%</td>
<td style="text-align: left;">世界知识、口语化表达</td>
</tr>
<tr>
<td style="text-align: left;">书籍 (Books)</td>
<td style="text-align: left;">20%</td>
<td style="text-align: left;">长篇连贯性、正式文风、深度知识</td>
</tr>
<tr>
<td style="text-align: left;">学术/科技 (Academic)</td>
<td style="text-align: left;">15%</td>
<td style="text-align: left;">专业知识、逻辑推理</td>
</tr>
<tr>
<td style="text-align: left;">代码 (Code)</td>
<td style="text-align: left;">15%</td>
<td style="text-align: left;">代码生成、逻辑推理</td>
</tr>
<tr>
<td style="text-align: left;">对话 (Dialogue)</td>
<td style="text-align: left;">10%</td>
<td style="text-align: left;">多轮交互、角色扮演</td>
</tr>
</tbody>
</table>
<h2 id="33-token">3.3 Token 预算到数据集分解方法</h2>
<p>宏观配比需要落地为具体的、可执行的数据集采购和处理计划。这一步的核心工作是“连连看”：将 Token 预算与现实世界的数据集对应起来。</p>
<p>以下是一个示例性的分解表（仅为示意，实际操作需更详）：</p>
<p>| 数据集名称 | 模态 | 来源 | 质量分层 | 预估 Token (万亿) | 占该模态比例 |</p>
<table>
<thead>
<tr>
<th style="text-align: left;">数据集名称</th>
<th style="text-align: left;">模态</th>
<th style="text-align: left;">来源</th>
<th style="text-align: left;">质量分层</th>
<th style="text-align: left;">预估 Token (万亿)</th>
<th style="text-align: left;">占该模态比例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">RefinedWeb (EN)</td>
<td style="text-align: left;">文本</td>
<td style="text-align: left;">开源</td>
<td style="text-align: left;">B</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">~15%</td>
</tr>
<tr>
<td style="text-align: left;">Common Crawl (CN)</td>
<td style="text-align: left;">文本</td>
<td style="text-align: left;">自采/清洗</td>
<td style="text-align: left;">B/C</td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">~23%</td>
</tr>
<tr>
<td style="text-align: left;">Books3 + 自采书籍</td>
<td style="text-align: left;">文本</td>
<td style="text-align: left;">开源+自采</td>
<td style="text-align: left;">A</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">~15%</td>
</tr>
<tr>
<td style="text-align: left;">The Stack v2</td>
<td style="text-align: left;">文本</td>
<td style="text-align: left;">开源</td>
<td style="text-align: left;">A/B</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">~15%</td>
</tr>
<tr>
<td style="text-align: left;">LAION-2B (text only)</td>
<td style="text-align: left;">文本</td>
<td style="text-align: left;">开源</td>
<td style="text-align: left;">C</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">~3%</td>
</tr>
<tr>
<td style="text-align: left;">... (其他文本)</td>
<td style="text-align: left;">文本</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">18</td>
<td style="text-align: left;">~28%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>文本总计</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><strong>65</strong></td>
<td style="text-align: left;"><strong>100%</strong></td>
</tr>
<tr>
<td style="text-align: left;">LAION-2B (image)</td>
<td style="text-align: left;">图像</td>
<td style="text-align: left;">开源</td>
<td style="text-align: left;">B/C</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">50%</td>
</tr>
<tr>
<td style="text-align: left;">COYO-700M</td>
<td style="text-align: left;">图像</td>
<td style="text-align: left;">开源</td>
<td style="text-align: left;">B</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">20%</td>
</tr>
<tr>
<td style="text-align: left;">自采高质量图库</td>
<td style="text-align: left;">图像</td>
<td style="text-align: left;">自采</td>
<td style="text-align: left;">A</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">30%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>图像总计</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><strong>10</strong></td>
<td style="text-align: left;"><strong>100%</strong></td>
</tr>
<tr>
<td style="text-align: left;">LibriSpeech</td>
<td style="text-align: left;">音频</td>
<td style="text-align: left;">开源</td>
<td style="text-align: left;">A</td>
<td style="text-align: left;">0.1</td>
<td style="text-align: left;">1%</td>
</tr>
<tr>
<td style="text-align: left;">YouTube 音轨 (部分)</td>
<td style="text-align: left;">音频</td>
<td style="text-align: left;">自采</td>
<td style="text-align: left;">B</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">80%</td>
</tr>
<tr>
<td style="text-align: left;">... (其他音频)</td>
<td style="text-align: left;">音频</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">1.9</td>
<td style="text-align: left;">19%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>音频总计</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><strong>10</strong></td>
<td style="text-align: left;"><strong>100%</strong></td>
</tr>
<tr>
<td style="text-align: left;">YouTube 视频 (部分)</td>
<td style="text-align: left;">视频</td>
<td style="text-align: left;">自采</td>
<td style="text-align: left;">B</td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">80%</td>
</tr>
<tr>
<td style="text-align: left;">Academic Video Sets</td>
<td style="text-align: left;">视频</td>
<td style="text-align: left;">开源</td>
<td style="text-align: left;">A</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">20%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>视频总计</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><strong>15</strong></td>
<td style="text-align: left;"><strong>100%</strong></td>
</tr>
</tbody>
</table>
<h2 id="34">3.4 课程与退火</h2>
<p>一次性将 100T 的混合数据投喂给模型并非最优策略。我们应采用课程学习（Curriculum Learning）和采样温度退火（Sampling Temperature Annealing）的策略，引导模型从易到难、从纯到杂地学习。</p>
<p><strong>课程学习 (Curriculum):</strong>
将训练过程划分为不同阶段，每个阶段的数据配方有所侧重。</p>
<ul>
<li><strong>阶段一 (0-1T tokens):</strong> <strong>基础能力期</strong>。主要使用高质量、长依赖的文本（书籍、代码）和高质量的图文对。目标是快速建立模型的语言基础和初步的图文对齐能力。</li>
<li><strong>阶段二 (1-5T tokens):</strong> <strong>多模扩展期</strong>。逐步引入音频和视频数据，同时增加通用网页文本的比例。目标是扩展模型对多模态的感知和理解能力。</li>
<li><strong>阶段三 (5T-10T tokens):</strong> <strong>能力融合与强化期</strong>。全面使用所有模态和质量层级的数据采用最终的混合配比。目标是让模型在复杂的、噪声更多的数据中学习鲁棒的表示，并融合所有能力。</li>
</ul>
<p><strong>采样退火 (Annealing):</strong>
在数据混合采样时，通过一个温度系数 <code>T</code> 来控制不同数据集的采样概率。数据集 <code>i</code> 的采样概率 <code>P(i)</code> 可以定义为：
$P(i) \propto w_i^{1/T}$
其中 <code>w_i</code> 是数据集 <code>i</code> 的基础权重。</p>
<ul>
<li><strong>训练初期 (T → ∞):</strong> 采样趋于均匀，模型“探索”更多样的数据。</li>
<li><strong>训练后期 (T → 1):</strong> 采样概率趋于 <code>w_i</code>，模型“利用”权重更高（通常是质量更高）的数据进行精调。
这种从宽泛到聚焦的策略，有助于模型稳定收敛。</li>
</ul>
<h2 id="35">3.5 质量分层与权重</h2>
<p>并非所有数据都生而平等。对数据进行质量分层，并在采样时赋予不同权重，是提升训练效率和模型最终性能的关键。</p>
<p><strong>质量分层定义:</strong></p>
<ul>
<li><strong>A 层 (Exemplary):</strong> 黄金标准数据。例如，经过专业编辑的书籍、经代码审查的开项目、学术论文、高质量的播客转录、专业制作的教学视频。这类数据信噪比极高。</li>
<li><strong>B 层 (Good):</strong> 质量较好的数据。例如，经过严格过滤的高赞网页内容 (如知乎、Stack Overflow)、主流开源项目的代码、大部分 YouTube 教育频道内容。</li>
<li><strong>C 层 (Acceptable):</strong> 大规模但噪声较多的数据。例如，未经精细过滤的 Common Crawl 网页、一般的网络视频和音频。需要强力的数据清洗手段。</li>
</ul>
<p><strong>权重策略:</strong>
我们应该<strong>过采样 (oversample)</strong> 高质量数据，<strong>欠采样 (undersample)</strong> 低质量数据。即使 A 层数据在总量上只占 1-5%，但在训练采样时，其被抽中的概率可能被提升到 10-20%。</p>
<p><strong>经验法则 (Rule-of-Thumb):</strong>
A:B:C 层的数据量级比可能是 1:10:100，但其采样权重比可以设为 3:2:1。这意味着模型“看到”A层数据的频率远高于其在原始数据池中的自然频率。</p>
<h2 id="36">3.6 开源语料与自采的组合策略</h2>
<p>完全依赖采数据成本高、周期长；完全依赖开源数据则可能面临数据陈旧、覆盖不足、版权模糊等问题。因此，采用“开源为主，自采为辅”的组合策略最为实际。</p>
<ul>
<li><strong>开源语料 (70-80%):</strong> 充分利用社区已经清洗和标注好的大规模数据集，如 The Pile, RedPajama, C4, LAION 等。这能极大地节约前期的数据处理成本，构成我们数据池的“基本盘”。<strong>核心思想是“站在巨人的肩膀上”</strong>。</li>
<li><strong>自采数据 (20-30%):</strong> 战略性地进行自采，以满足特定需求：<ul>
<li><strong>时效性 (Recency):</strong> 抓取近期的网页、新闻、论文，确保模型知识不过时。</li>
<li><strong>领域覆盖 (Domain Coverage):</strong> 针对开源数据中覆盖不足的特定中文领域（如特定论坛、社交媒体）进行补充。</li>
<li><strong>合规性 (Compliance):</strong> 自采数据能更好地控制来源，确保遵循 robots.txt 和服务条款（TOS），降低法律风险。</li>
</ul>
</li>
</ul>
<h2 id="37">3.7 合成数据的角色与比例</h2>
<p>合成数据是弥补数据采集短板、增强模型特定能力的“精确制导武器”。</p>
<p><strong>应用场景:</strong></p>
<ul>
<li><strong>补齐长尾:</strong> 对稀有领域、专业知识，通过大模型（如 GPT-4）生成问答对或文章。</li>
<li><strong>对齐强化:</strong> 生成高质量的“指令-代码”、“问题-SQL”等配对数据，强化模型的工具使用能力。</li>
<li><strong>安全与对齐:</strong> 构造大量安全红队问题和期望的回答，用于模型的价值观对齐。</li>
<li><strong>多模态数据增强:</strong> 使用高质量 TTS（Text-to-Speech）合成带精准时间戳的音频，或为视频生成高质量描述。</li>
</ul>
<p><strong>比例控制:</strong>
合成数据是一把双刃剑。过度使用可能导致模型学到生成模型的“偏见”和“幻觉”，出现模式崩溃（mode collapse）。</p>
<p><strong>经验法则 (Rule-of-Thumb):</strong>
在预训练阶段，合成数据的比例应严格控制在 <strong>总 Token 量的 5% 以内</strong>。其主要价值体现在后续的对齐微调（SFT）阶段。</p>
<h2 id="38">3.8 数据版本化与数据卡</h2>
<p><strong>数应视作与代码同等重要的一等公民。</strong></p>
<p><strong>数据版本化:</strong>
使用 DVC (Data Version Control) 或简单的对象存储路径命名约定（如 <code>s3://my-bucket/datasets/common_crawl/v2.1_filtered/</code>）来管理数据版本。</p>
<ul>
<li><strong>可复现性:</strong> 保证任何一次训练实验都可以精确追溯到所使用的数据版本。</li>
<li><strong>调试:</strong> 当模型表现异常时，可以快速回溯到数据变更，定位问题。</li>
<li><strong>增量更新:</strong> 便于管理数据的增量清洗和扩充。</li>
</ul>
<p><strong>数据卡 (Data Card):</strong>
为每个数据集或数据版本创建一个 <code>datacard.md</code> 文件，记录其“元宇宙”。</p>
<ul>
<li><strong>内容:</strong> 数据来源、许可证、采集时间、处理流程（清洗、去重、过滤规则）、已知偏见、PII（个人可识别信息）处理方法、Token 数量、语言分布等。</li>
<li><strong>价值:</strong> 这是负责任 AI 的核心实践，有助于提升透明度、辅助合规审查、并为下游用户提供关键信息。</li>
</ul>
<h2 id="39">3.9 本章小结</h2>
<p>本章系统阐述了构一个百亿亿级多模态数据池的配方设计方法论。</p>
<ul>
<li><strong>顶层设计:</strong> 从语言、模态、领域的宏观配比出发，确立模型的能力蓝图。</li>
<li><strong>落地执行:</strong> 将宏观预算细化分解到具体的数据集，形成可执行的计划。</li>
<li><strong>动态优化:</strong> 采用课程学习和采样退火策略，引导模型高效、稳定地学习。</li>
<li><strong>质量为王:</strong> 通过质量分层和加权采样，放大高质量数据的效用。</li>
<li><strong>组合策略:</strong> 平衡利用开源、自采和合成数据，实现成本、时效和质量的最优解。</li>
<li><strong>工程实践:</strong> 坚持数据版本化和数据卡制度，将数据管理提升到软件工程的高度。</li>
</ul>
<p>一个卓越的数据配方，是通往强大、可靠、负责任的多模态大模型的第一步，也是最关键的一步。</p>
<h2 id="310-gotchas">3.10 常见陷阱与错误 (Gotchas)</h2>
<ol>
<li><strong>“数量崇拜”陷阱 (Quantity over Quality):</strong> 错误地认为数据量越大越好，而忽视了低质量数据对模型的“毒害”作用1T 的 A 层数据价值远超 10T 的 C 层未清洗数据。</li>
<li><strong>“静态配方”僵局 (Static Recipe):</strong> 从头到尾使用完全相同的采样混合比。这会错过通过课程学习引导模型成长的机会，可能导致训练早期不稳定或后期收敛缓慢。</li>
<li><strong>测试集/验证集污染 (Test/Validation Set Contamination):</strong> 这是最严重且最常见的错误之一。在构建训练数据池时，必须用尽一切手段（如 MinHash, SimHash, Embedding-based search）确保训练数据与所有下游评测集（包括私有评测集）没有重叠。否则，评测结果将毫无意义。</li>
<li><strong>忽视许可证 (License Blindness):</strong> 在大规模使用开源或抓取数据时，未仔细审查每个数据集的许可证（License）和服务条款（TOS）。这可能导致严重的法律和合规风险，甚至迫使模型下架。</li>
<li><strong>数据版本混乱 (Versioning Chaos):</strong> 未对数据处理的每一步进行版本化管理。当需要复现某个实验或排查数据问时，这将是一场灾难。</li>
<li><strong>合成数据滥用 (Synthetic Data Overuse):</strong> 过度依赖合成数据，尤其是在预训练阶段，可能导致模型思维僵化，多样性降低，并继承生成模型的缺陷。合成数据是“补品”，不能当“主食”。</li>
</ol>
            </article>
            
            <nav class="page-nav"><a href="chapter2.html" class="nav-link prev">← 项目管理与里程碑</a><a href="chapter4.html" class="nav-link next">第 4 章 文本数据：抓取、清洗、去重与质量分层 →</a></nav>
        </main>
    </div>
</body>
</html>