<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第 4 章 文本数据：抓取、清洗、去重与质量分层</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">index.md（导读与目录）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 1: 总览与技术路线</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">项目管理与里程碑</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第三章：数据配方设计（100T token 池）</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 4 章 文本数据：抓取、清洗、去重与质量分层</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 5 章 — 音频数据：合规抓取、ASR 对齐、RVQ 离散化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 6 章 — 视频数据：合规抓取、切片与时空离散化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 7 章 — 图像数据：采集、质量打分与离散化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Tokenizer 与词表：多模扩词、特殊符与对齐</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">模型结构与超参数（1B/10B）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十章：训练基础设施（Megatron @ 256×H100）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 11 章：数据混采与课程策略（10T token 单轮）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十二章：监控与可观测性</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十三章 评测体系：从自回归困惑度到视觉语言指标</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十四章：安全与合规</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十五章：交付与落地（Checkpoint & 蒸馏）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="appendixA.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">附录 A：计算与容量估算（公式与算例）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="appendixB.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">附录 B：工具链与脚手架（配置与模板）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="appendixC.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">附录 C — 常见故障与排障（Runbook）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="4">第 4 章 文本数据：抓取、清洗、去重与质量分层</h1>
<h2 id="41">4.1 开篇与学习目标</h2>
<p>文本数据是多模态模型的基石。尽管我们的目标是构建一个能理解视频、音频和图像的模型，但高质量的文本语料不仅是模型语言能力的核心来源，也是连接和描述其他模态的“通用语”。一个在劣质文本上训练的模型，其推理、逻辑和生成能力将存在根本性缺陷。本章将深入探讨如何从零开始，构建一个万亿（Trillion）级别 token 的高质量文本数据集。我们将覆盖从数据源选择、合规抓取，到多阶段清洗、去重，再到最终的质量分层和预算分配的全过程。</p>
<p><strong>学习目标:</strong></p>
<ul>
<li>掌握大规模文本数据的来源选择与合规性审查。</li>
<li>理解从网页抓取原始文本并进行有效解析的技术。</li>
<li>学习如何应用多阶段过滤策略（包括启发式、小模型和分类器）来提升数据质量。</li>
<li>掌握精确去重和近似去重的核心技术（如 MinHash LSH），并理解其在跨语言场景的应用。</li>
<li>能够设计并执行一个具体的数据集级 token 预算方案。</li>
</ul>
<h2 id="42">4.2 数据来源与合规</h2>
<p>选择数据源是数据工程的第一步，它直接决定了数据质量的上限和法律风险的下限。我们的目标是构建一个多样化、高质量且合规的数据池。</p>
<p><strong>核心原则：</strong></p>
<ol>
<li><strong>质量优先</strong>: 优先选择经过编辑或同行评审的内容，如百科、书籍、学术论文。</li>
<li><strong>多样性</strong>: 广泛覆盖不同领域，包括新闻、技术博客、论坛讨论、代码等，以增强模型的通用能力。</li>
<li><strong>合规性</strong>: 严格遵守每个数据源的 <code>robots.txt</code> 协议、服务条款（TOS）和内容许可（License）。这是规避法律风险的生命线。</li>
</ol>
<p>以下是一些主流数据源及其特点：</p>
<p>| 数据源类型 | 示例                                   | 优点                               | 缺点与合规注意事项                                     |</p>
<table>
<thead>
<tr>
<th style="text-align: left;">数据源类型</th>
<th style="text-align: left;">示例</th>
<th style="text-align: left;">优点</th>
<th style="text-align: left;">缺点与合规注意事项</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>百科</strong></td>
<td style="text-align: left;">Wikipedia (多语言), Baidu Baike</td>
<td style="text-align: left;">结构化、高质量、事实性强</td>
<td style="text-align: left;">领域覆盖有限，内容更新可能滞后</td>
</tr>
<tr>
<td style="text-align: left;"><strong>书籍</strong></td>
<td style="text-align: left;">Common Crawl Books, Project Gutenberg</td>
<td style="text-align: left;">长篇连贯、语法规范、深度内容</td>
<td style="text-align: left;">版权复杂，需仔细筛选公共领域或开放许可的书籍</td>
</tr>
<tr>
<td style="text-align: left;"><strong>网页</strong></td>
<td style="text-align: left;">Common Crawl (CC), C4, RefinedWeb</td>
<td style="text-align: left;">规模巨大、覆盖面广、时效性强</td>
<td style="text-align: left;">质量参差不齐，含大量广告、导航栏等噪声，需强力清洗</td>
</tr>
<tr>
<td style="text-align: left;"><strong>代码</strong></td>
<td style="text-align: left;">The Stack, GitHub</td>
<td style="text-align: left;">训练代码生成与理解能力</td>
<td style="text-align: left;">需处理多种编程语言，许可证（GPL, MIT等）需严格跟踪</td>
</tr>
<tr>
<td style="text-align: left;"><strong>新闻</strong></td>
<td style="text-align: left;">新闻网站 RSS Feeds, 共新闻数据集</td>
<td style="text-align: left;">语法正式、时事性强</td>
<td style="text-align: left;">可能存在观点偏见，需注意来源平衡</td>
</tr>
<tr>
<td style="text-align: left;"><strong>论坛/社交</strong></td>
<td style="text-align: left;">Reddit, Stack Exchange, 知乎</td>
<td style="text-align: left;">对话性强、口语化、覆盖长尾问题</td>
<td style="text-align: left;">噪声多、毒性内容风险高，用户生成内容（UGC）版权需注意</td>
</tr>
<tr>
<td style="text-align: left;"><strong>学术</strong></td>
<td style="text-align: left;">arXiv, PubMed Central</td>
<td style="text-align: left;">专业性强、逻辑严密</td>
<td style="text-align: left;">格式（LaTeX, PDF）解析复杂，领域非常垂直</td>
</tr>
</tbody>
</table>
<p>在启动任何抓取任务前，法务团队必须介入，对每个目标来源的许可和TOS进行评估，建立一份“允许抓取清单”。</p>
<h2 id="43">4.3 抓取与解析</h2>
<p>将原始网页转化为干净的文本，是一个充满挑战的提取、转换和加载（ETL）过程。</p>
<ul>
<li>
<p><strong>抓取策略</strong>:</p>
<ul>
<li><strong>尊重 <code>robots.txt</code></strong>: 这是网络爬虫的“君子协定”。程序必须自动解析并遵守其 <code>Disallow</code> 规则。</li>
<li><strong>速率限制</strong>: 为避免对目标服务器造成大压力（以及被封禁），需设置合理的抓取延迟和并发数。采用分布式爬虫时，IP轮换是标准实践。</li>
<li><strong>头部信息</strong>: 模拟真实浏览器 <code>User-Agent</code>，处理 <code>Cookies</code> 和 <code>session</code>，以访问需要登录或动态交互的内容。</li>
</ul>
</li>
<li>
<p><strong>解析与内容提取</strong>:</p>
<ul>
<li><strong>HTML 清洗</strong>: 原始 HTML 充满了标签、脚本和样式。首要任务是移除这些非内容元素。</li>
<li><strong>模板与锅炉板去除 (Boilerplate Removal)</strong>: 网页中的页眉、页脚、导航栏、广告等属于“锅炉板”内容，对模型训练是纯粹的噪声。可以使用 <code>trafilatura</code>, <code>BeautifulSoup</code> 等库，结合启发式规则（如文本密度、链接密度）进行剔除。</li>
<li><strong>动态页面处理</strong>: 对于大量使用 JavaScript 渲染的“单页应用”（SPA），简单的 HTTP 请求无法获取完整内容。此时需要动用如 <code>Selenium</code> 或 <code>Playwright</code> 这样的无头浏览器。但由于资源消耗巨大，此方法应仅用于关键且无法通过其他方式获取的网站。</li>
</ul>
</li>
</ul>
<p>一个典型的抓取解析流程如下（ASCII 图）：</p>
<div class="codehilite"><pre><span></span><code><span class="k">[URL Queue] -&gt; [Distributed Crawlers] -&gt; [Raw HTML Storage (e.g., S3)]</span>
<span class="w">      </span><span class="na">^                  |                      |</span>
<span class="w">      </span><span class="na">|                  v                      v</span>
<span class="k">[URL Discovery] &lt;- [HTML Parser &amp; Cleaner] -&gt; [Clean Text Storage]</span>
</code></pre></div>

<h2 id="44">4.4 语言识别与分布控制</h2>
<p>为了实现中英 90%、其他语种 10% 的目标配比，我们需要在文档级别进行可靠的语言识别。</p>
<ul>
<li>
<p><strong>工具选择</strong>:</p>
<ul>
<li><code>fastText</code> 语言识别模型：速度极快，精度高，支持数百种语言，是工业界大规模处理的首选。</li>
<li><code>pycld3</code>: Google 的紧凑语言检测器3的 Python 封装，同样高效可靠。</li>
</ul>
</li>
<li>
<p><strong>实践流程</strong>:</p>
<ol>
<li>对每个从上一阶段获得的干净文档，取前 N 个字符（例如 1024）进行语言识别。</li>
<li>为每个文档打上语言标签（如 <code>lang_en</code>, <code>lang_zh_cn</code>）和置信度分数。</li>
<li>根据置信度阈值（如 &gt; 0.8过滤掉无法确定语言的文档。</li>
<li>在构建最终训练批次时，根据目标语言分布（90/10）对不同语言的文档进行采样。</li>
</ol>
</li>
</ul>
<h2 id="45">4.5 质量过滤</h2>
<p>这是确保最终数据集“营养丰富”而非“充满垃圾”的核心环节。我们采用一个多阶段的过滤漏斗，逐步筛除低质量内容。</p>
<p><strong>数据质量过滤漏斗 (Data Quality Filtering Funnel):</strong></p>
<ol>
<li>
<p><strong>启发式过滤 (Heuristics-based Filtering)</strong>:</p>
<ul>
<li><strong>长度过滤</strong>: 移除过短（如 &lt; 200 字符）或过长（如 &gt; 100,000 字符）的文档。</li>
<li><strong>符号比例</strong>: 计算特殊符号、数字或非字母字符的比例，移除“乱码”或代码片段。</li>
<li><strong>词汇多样性</strong>: 使用“词元/类型比”（Token-Type Ratio, TTR）过滤重复性极高的文本（如“你好你好你好…”）。</li>
<li><strong>停用词检测</strong>: 确保文档包含足够比例的停用词，这通常是自然语言的一个标志。</li>
</ul>
</li>
<li>
<p><strong>分类器过滤 (Classifier-based Filtering)</strong>:</p>
<ul>
<li><strong><code>fastText</code> 主题/质量分类器</strong>: 这是一个非常有效的“经验法则”。我们可以准备一个小的、高质量的“黄金”语料（如部分 Wikipedia）和一个已知的低质量语料（如从 CC 中抽取的含成人、垃圾广告内容的样本），然后训练一个 <code>fastText</code> 二分类模型。用这个模型为所有文档打一个质量分，并设定阈值。</li>
<li><strong>毒性/仇恨言论/PII 检测</strong>: 使用预训练的文本分类模型（如 <code>Jigsaw</code> 挑战赛的模型）或内部模型，识别并移除或标记化处理有害内容。对于个人身份信息（PII），可使用正则表达式和命名实体识别（NER）模型进行检测和脱敏。</li>
</ul>
</li>
<li>
<p><strong>小模型困惑度过滤 (Small Model Perplexity Filtering)</strong>:</p>
<ul>
<li><strong>原理</strong>: 使用一个中等规模（如 1B-3B）的预训练语言模型（例如 GPT-2 或一个早期的内部模型）来计算每个文档的困惑度（Perplexity, PPL）。</li>
<li><strong>直觉</strong>: PPL 衡量了模型对一段文本的“讶程度”。高质量、流畅的自然语言（如维基百科）通常具有较低的 PPL；而机器生成的、无意义的或语法错误的文本则具有较高的 PPL。</li>
<li><strong>操作</strong>: 对每个语言，按 PPL 从低到高对所有文档排序，移除 PPL 最高的 5%-10% 的文档。</li>
</ul>
</li>
</ol>
<h2 id="46">4.6 去重</h2>
<p>重复的数据会使模型在训练时“偷懒”，降低其泛化能力，并可能导致在生成时陷入重复循环。</p>
<ul>
<li>
<p><strong>精确去重 (Exact Deduplication)</strong>:</p>
<ul>
<li>对每个文档进行规范化处理（转小写、去标点、去空白）。</li>
<li>计算文档的哈希值（如 SHA256）。</li>
<li>存储所有哈希值，并丢弃任何哈希值已存在的新文档。这一步可以用哈希集合（HashSet）高效完成。</li>
</ul>
</li>
<li>
<p><strong>近似去重 (Near-Deduplication)</strong>:</p>
<ul>
<li><strong>挑战</strong>: 许多文档只是略有改动（如新闻稿的不同版本、网页模板的微小变化），精确去重无法捕捉。</li>
<li><strong>解决方案: MinHash LSH (Locality-Sensitive Hashing)</strong><ol>
<li><strong>分词 (Shingling)</strong>: 将文档分解为重叠的 n-grams（例如 5-grams 或 13-grams 的字符序列）。</li>
<li><strong>哈希 (Hashing)</strong>: 将每个 shingle 哈希成一个整数。</li>
<li><strong>最小哈希 (Min-Hashing)</strong>: 使用 K 个不同的哈希函数，找出每个文档 shingle 集合中经这 K 个函数计算后的 K 个最小值，形成文档的 MinHash 签名（一个 K 维向量）。</li>
<li><strong>局部敏感哈希 (LSH)</strong>: 将 K 维签名分段（banding），只要任何一段完全相同，就将两个文档视为“候选对”。</li>
<li><strong>验证</strong>: 对所有候选对，计算其真实的 Jaccard 相似度，超过阈值（如 0.8）的即判为重复，只保留其一。</li>
</ol>
</li>
<li><strong>跨语种去重</strong>: 对于中英文等，可以先将一种语言翻译成另一种（使用低成本的机器翻译API），再进行近似去重；或者使用多语言句子嵌入（如 LaBSE），在向量空间中寻找近邻来识别语义重复。</li>
</ul>
</li>
</ul>
<h2 id="47-token">4.7 Token 化、长度布与长序列采样</h2>
<p>在完成所有清洗和去重工作后，我们需要将文本数据转化为模型能理解的格式。</p>
<ul>
<li><strong>Token 化</strong>: 使用项目统一的 Tokenizer（本指南中为 Qwen Tokenizer 的扩展版），将所有文档处理成 token ID 序列。</li>
<li><strong>长度分布分析</strong>: 统计所有文档 token 化后的长度分布。这个直方图至关重要，它能告诉我们：<ul>
<li>数据集中长序列（如超过 8K 或 32K token）的比例是否足够。</li>
<li>如果长序列稀缺，我们需要有针对性地补充长文本数据（如书籍、代码库），或者采用文档拼接（concatenation）策略来人为制造长序列。</li>
</ul>
</li>
<li><strong>长序列采样</strong>: 在数据打包（packing）阶段，确保有策略地采样长文档，以训练模型的长上下文理解能力。这可能是一个课程学习策略的一部分（详见第 11 章）。</li>
</ul>
<h2 id="48-token">4.8 数据集级 token 预算与表格</h2>
<p>将我们宏大的 30T token 文本数据池（假设文本占总多模态 token 的 30%）分解到具体的数据集上。这是一个结合了数据质量、多样性和可用性的艺术。</p>
<p><strong>文本数据配方示例 (目标：~30T tokens)</strong></p>
<p>| 数据集名称       | 来源/构建方式                                    | 原始大小 (TB) | 清洗/去重后 Token (Billion) | 占比 (%) | 质量分层 | 许可证/备注                                 |</p>
<table>
<thead>
<tr>
<th style="text-align: left;">数据集名称</th>
<th style="text-align: left;">来源/构建方式</th>
<th style="text-align: left;">原始大小 (TB)</th>
<th style="text-align: left;">清洗/去重后 Token (Billion)</th>
<th style="text-align: left;">占比 (%)</th>
<th style="text-align: left;">质量分层</th>
<th style="text-align: left;">许可证/备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Wikipedia (中/英)</strong></td>
<td style="text-align: left;">Wikimedia Dumps</td>
<td style="text-align: left;">~0.1</td>
<td style="text-align: left;">800</td>
<td style="text-align: left;">2.7%</td>
<td style="text-align: left;">A+</td>
<td style="text-align: left;">CC-BY-SA 3.0</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Books (中/英)</strong></td>
<td style="text-align: left;">CC-Books, 自有语料</td>
<td style="text-align: left;">~2.0</td>
<td style="text-align: left;">4,000</td>
<td style="text-align: left;">13.3%</td>
<td style="text-align: left;">A+</td>
<td style="text-align: left;">公共领域, 需逐一审查版权</td>
</tr>
<tr>
<td style="text-align: left;"><strong>RefinedWeb (英)</strong></td>
<td style="text-align: left;">从 Common Crawl 精炼</td>
<td style="text-align: left;">~5.0</td>
<td style="text-align: left;">5,000</td>
<td style="text-align: left;">16.7%</td>
<td style="text-align: left;">A</td>
<td style="text-align: left;">OSCC-BY 4.0</td>
</tr>
<tr>
<td style="text-align: left;"><strong>C4 (中/英)</strong></td>
<td style="text-align: left;">从 Common Crawl 清洗</td>
<td style="text-align: left;">~20.0</td>
<td style="text-align: left;">7,000</td>
<td style="text-align: left;">23.3%</td>
<td style="text-align: left;">B</td>
<td style="text-align: left;">ODC-By, 需进一步清洗</td>
</tr>
<tr>
<td style="text-align: left;"><strong>The Stack (代码)</strong></td>
<td style="text-align: left;">从 GitHub 抓取</td>
<td style="text-align: left;">~3.0</td>
<td style="text-align: left;">3,000</td>
<td style="text-align: left;">10.0%</td>
<td style="text-align: left;">A</td>
<td style="text-align: left;">多种开源许可，需跟踪</td>
</tr>
<tr>
<td style="text-align: left;"><strong>ArXiv (英)</strong></td>
<td style="text-align: left;">arXiv API</td>
<td style="text-align: left;">~1.5</td>
<td style="text-align: left;">1,500</td>
<td style="text-align: left;">5.0%</td>
<td style="text-align: left;">A</td>
<td style="text-align: left;">arXiv License</td>
</tr>
<tr>
<td style="text-align: left;"><strong>新闻 (中/英)</strong></td>
<td style="text-align: left;">RSS, 公共数据集</td>
<td style="text-align: left;">~10.0</td>
<td style="text-align: left;">3,000</td>
<td style="text-align: left;">10.0%</td>
<td style="text-align: left;">B+</td>
<td style="text-align: left;">需遵守各新闻源 TOS</td>
</tr>
<tr>
<td style="text-align: left;"><strong>社交/论坛 (中/英)</strong></td>
<td style="text-align: left;">Reddit, StackEx, 知乎等</td>
<td style="text-align: left;">~15.0</td>
<td style="text-align: left;">4,500</td>
<td style="text-align: left;">15.0%</td>
<td style="text-align: left;">B-</td>
<td style="text-align: left;">UGC 内容, 需强力过滤毒性和 PII</td>
</tr>
<tr>
<td style="text-align: left;"><strong>其他语种</strong></td>
<td style="text-align: left;">多源混合 (mC4 等)</td>
<td style="text-align: left;">~10.0</td>
<td style="text-align: left;">1,200</td>
<td style="text-align: left;">4.0%</td>
<td style="text-align: left;">C</td>
<td style="text-align: left;">作为长尾，支撑多语言能力</td>
</tr>
<tr>
<td style="text-align: left;"><strong>总计</strong></td>
<td style="text-align: left;">-</td>
<td style="text-align: left;"><strong>~66.6</strong></td>
<td style="text-align: left;"><strong>30,000 (30T)</strong></td>
<td style="text-align: left;"><strong>100%</strong></td>
<td style="text-align: left;">-</td>
<td style="text-align: left;">-</td>
</tr>
</tbody>
</table>
<h2 id="49">4.9 本章小结</h2>
<p>本章详细阐述了构建大规模、高质量文本数据预料库的全过程。我们强调了这是一个系统工程，始于合规的数据源选择，经过细致的抓取与解析，再通过一个包括启发式、分类器和模型困惑度在内的多阶段过滤漏斗。我们还讨论了精确和近似去重的必要性与技术实现，最后通过一个具体的 token 预算表将宏观目标落地。高质量的文本数据是模型能力的根本保障，在这环节投入再多的精力也不为过。</p>
<h2 id="410-gotchas">4.10 常见陷阱与错误 (Gotchas)</h2>
<ol>
<li><strong>合规性疏忽</strong>: 在项目后期发现早期抓取的数据存在严重的版权或TOS问题，导致需要废弃大量数据，甚至引发法律纠纷。<strong>调试技巧</strong>: 在项目启动时就让法务团队介入，建立数据源白名单制度。</li>
<li><strong>“脏”数据渗透</strong>: 过滤规则过于宽松，导致大量低质量、模板化或有害内容进入训练集，模型“学坏”了，表现为生成内容逻辑混乱、充满偏见或重复。<strong>调试技巧</strong>: 建立数据抽样审计机制，定期人工检查各阶段的样本，并可视化关键统计指标（如 PPL 分布、语言分布），发现异常立即告警。</li>
<li><strong>过度清洗</strong>: 过滤规则过于严苛，误伤了大量有价值的非标准文本（如诗歌、代码、方言），导致模型在这些领域的能力缺失。<strong>调试技巧</strong>: 在设置过滤规则时，不仅要看被“丢弃”的数据，也要抽样检查，确没有“错杀”。对特定领域（如代码）应采用专门的清洗策略。</li>
<li><strong>去重不彻底</strong>: 仅使用精确去重，忽略了大量近似重复的内容。这会导致评测指标虚高（因为模型记住了评测集中的相似样本），实际泛化能力差。<strong>调试技巧</strong>: 必须实施近似去重。定期计算训练数据与评测集、验证集之间的 n-gram 重叠率或 MinHash 相似度，确保没有数据泄漏。</li>
<li><strong>PII 脱敏失败</strong>: PII 检测与移除方案存在漏洞，导致模型记忆并可能泄露用户隐私。<strong>调试技巧</strong>: 使用更强的 PII 检测工具，并进行红队测试，主动探查模型是否会泄露在训练数据中见过的敏感信息。对高风险数据源进行更严格的匿名化处理。</li>
<li><strong>Token 化不一致</strong>: 在数据处理和模型训练阶段使用了不同版本或配置的 Tokenizer，导致灾难性的结果。<strong>调试技巧</strong>: 将 Tokenizer 的版本和配置文件作为项目核心资产进行严格的版本控，确保所有流程使用唯一的、确定的 Tokenizer。</li>
</ol>
            </article>
            
            <nav class="page-nav"><a href="chapter3.html" class="nav-link prev">← 第三章：数据配方设计（100T token 池）</a><a href="chapter5.html" class="nav-link next">第 5 章 — 音频数据：合规抓取、ASR 对齐、RVQ 离散化 →</a></nav>
        </main>
    </div>
</body>
</html>