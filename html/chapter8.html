<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>Tokenizer 与词表：多模扩词、特殊符与对齐</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">index.md（导读与目录）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 1: 总览与技术路线</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">项目管理与里程碑</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第三章：数据配方设计（100T token 池）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 4 章 文本数据：抓取、清洗、去重与质量分层</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 5 章 — 音频数据：合规抓取、ASR 对齐、RVQ 离散化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 6 章 — 视频数据：合规抓取、切片与时空离散化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 7 章 — 图像数据：采集、质量打分与离散化</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Tokenizer 与词表：多模扩词、特殊符与对齐</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">模型结构与超参数（1B/10B）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十章：训练基础设施（Megatron @ 256×H100）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 11 章：数据混采与课程策略（10T token 单轮）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十二章：监控与可观测性</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十三章 评测体系：从自回归困惑度到视觉语言指标</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十四章：安全与合规</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="tokenizer">Tokenizer 与词表：多模扩词、特殊符与对齐</h1>
<h2 id="81">8.1 开篇与学习目标</h2>
<p>本章是连接数据与模型的关键桥梁。在前几章中，我们已经将各种模态的数据（文本、音频、视频、图像）处理成了标准化的格式，但它们仍然是异构的。为了让一个统一的自回归 Transformer 模型能够理解和生成这些数据，我们必须将它们转换成一种通用的语言——离散的 token 序列。本章的目标是设计并实现一个多模态 tokenizer 和一个统一的词汇表，它能够无缝地表示所有模态的信息。</p>
<p>学完本章，您将能够：</p>
<ul>
<li>理解为何以及如何在一个成熟的文本 tokenizer 基础上扩展多模态能力。</li>
<li>设计一套用于模态切换、分割和对齐的特殊符号系统。</li>
<li>掌握利用 <strong>RVQ</strong> (Residual Vector Quantization) 将连续特征（如音频、视频）离散化并整合进统词表的核心技术。</li>
<li>为长序列数据设计分块与拼接策略，并实现高效的样本打包（Packing）。</li>
<li>认识到词表版本管理的重要性及其对整个项目生命周ടിയ的影响。</li>
</ul>
<h2 id="82-qwen-tokenizer">8.2 文本沿用 Qwen tokenizer 的多模扩展</h2>
<p>对于一个以中英文为核心的多模态模型，从零开始训练一个文本 tokenizer 并非明智之举。成熟的开源 tokenizer（如 Qwen、LLaMA 等使用的 BPE tokenizer）已经在海量文本上进行了优化，具备高效、覆盖广、语义分组合理的优点。我们的策略是<strong>扩展（Extend）而非替换（Replace）</strong>。</p>
<p>我们选择 <strong>Qwen tokenizer</strong> 作为基础，主要基于以下几点：</p>
<ol>
<li><strong>中英双语优化</strong>：Qwen 的 tokenizer 对中英文语料都有很好的覆盖，符合我们数据配方中 90% 中英文的目标。</li>
<li><strong>词表规模适中</strong>：约 15 万的词表大小在表达能力和模型嵌入层大小之间取得了良好平衡。</li>
<li><strong>社区生态成熟</strong>：相关的预处脚本和社区支持较为完善，便于直接集成。</li>
</ol>
<p>扩展的方式是在其现有词表的基础上，预留出新的 token ID 空间，用于后续添加特殊符号和非文本模态的离散码本。</p>
<h2 id="83">8.3 模态特殊符与段标记</h2>
<p>为了让模型在处理长序列时能够区分不同模态的数据、理解其结构，我们需要引入一套结构化的特殊符号（Special Tokens）。这些符号是模型的“语法标记”，指导其如何解析输入和生成输出。</p>
<p>| 特殊符         | 功能描述                                                     | 示例                                                |</p>
<table>
<thead>
<tr>
<th style="text-align: left;">特殊符</th>
<th style="text-align: left;">功能描述</th>
<th style="text-align: left;">示例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><code>&lt;img&gt;</code></td>
<td style="text-align: left;">标志图像内容的开始</td>
<td style="text-align: left;"><code>&lt;img&gt; [IMG_1] [IMG_2] ... &lt;/img&gt;</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>&lt;/img&gt;</code></td>
<td style="text-align: left;">标志图像内容的结束</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"><code>&lt;aud&gt;</code></td>
<td style="text-align: left;">标志音频内容的开始</td>
<td style="text-align: left;"><code>&lt;aud&gt; [AUD_1] [AUD_2] ... &lt;/aud&gt;</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>&lt;/aud&gt;</code></td>
<td style="text-align: left;">标志音频内容的结束</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"><code>&lt;vid&gt;</code></td>
<td style="text-align: left;">标志视频内容的开始</td>
<td style="text-align: left;"><code>&lt;vid&gt; [VID_1] [VID_2] ... &lt;/vid&gt;</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>&lt;/vid&gt;</code></td>
<td style="text-align: left;">标志视频内容的结束</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"><code>&lt;|im_start|&gt;</code></td>
<td style="text-align: left;">对话或指令的起始标记</td>
<td style="text-align: left;"><code>&lt;|im_start|&gt;user\n你好&lt;|im_end|&gt;</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>&lt;|im_end|&gt;</code></td>
<td style="text-align: left;">对话或指令的结束标记</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"><code>&lt;|endoftext|&gt;</code></td>
<td style="text-align: left;">文档或样本的结束标记，用于样本打包（Packing）</td>
<td style="text-align: left;"><code>... 一段文本 ...&lt;|endoftext|&gt;</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>&lt;|sep|&gt;</code></td>
<td style="text-align: left;">通用分隔符，用于分隔不同语义块，如图像和其描述文本</td>
<td style="text-align: left;"><code>&lt;img&gt;...&lt;/img&gt; &lt;|sep|&gt; 一只猫的照片</code></td>
</tr>
</tbody>
</table>
<p>这些特殊符号需要被添加到 tokenizer 的词表中，并赋予独一无二的 token ID。在训练时，模型会学习到这些符号的语义功能。</p>
<h2 id="84-rvq">8.4 连续特征编码器 + RVQ 的码本并入统一词表</h2>
<p>这是多模态 tokenizer 的核心。图像、音频、视频本质上是连续的高维信号。我们的统一离散化策略分为两步：</p>
<ol>
<li><strong>编码（Encode）</strong>：使用一个预训练的、模态专用的编码器（如 ViT-VAE、Encodec）将原始数据块（如图像 patch、音频帧）压缩成低维的连续特征向量（latent vectors）。</li>
<li><strong>量化（Quantize）</strong>：使用 <strong>RVQ (Residual Vector Quantization)</strong> 将这些连续特征向量映射为离散的 token ID 序列。</li>
</ol>
<p><strong>RVQ 工作原理简介：</strong>
与 VQ-VAE 使用单个码（codebook）不同，RVQ 使用多个（例如 <code>N_q = 4</code> 或 <code>8</code>）码本。对于一个特征向量 <code>z</code>，RVQ 会逐步对其进行量化：</p>
<ol>
<li>在第一个码本 <code>C_1</code> 中找到最近的码字 <code>e_1</code>。</li>
<li>计算残差 <code>r_1 = z - e_1</code>。</li>
<li>在第二个码本 <code>C_2</code> 中为残差 <code>r_1</code> 找到最近的码字 <code>e_2</code>。</li>
<li>计算新的残差 <code>r_2 = r_1 - e_2</code>。</li>
<li>... 以此类推，直到经过所有 <code>N_q</code> 个码本。</li>
</ol>
<p>最终，原始向量 <code>z</code> 被近似表示为 <code>N_q</code> 个码字之和：<code>z ≈ e_1 + e_2 + ... + e_{N_q}</code>。而它的离散表示就是这 <code>N_q</code> 个码字对应的索引 <code>(idx_1, idx_2, ..., idx_{N_q})</code>。</p>
<p><strong>整合进统一词表：</strong>
我们将每个 RVQ 码本视为一个独立的“词汇集”。假设每个码本大小为 1024，我们有 8 个码本用于图像，8 个用于音频。我们可以在 Qwen 的词表之后，为这些码本保留连续的 ID 区块。</p>
<div class="codehilite"><pre><span></span><code><span class="k">[ ... 原始 Qwen 文本词表 (0 - 151642) ... ]</span>
<span class="k">[ ... 特殊符号 (151643 - 151700) ... ]</span>
<span class="na">--- RVQ 码本区域始 ---</span>
<span class="na">[ 图像码本 1 (151701 - 152724) ]  (1024 个 ID)</span>
<span class="na">[ 图像码本 2 (152725 - 153748) ]  (1024 个 ID)</span>
<span class="na">...</span>
<span class="na">[ 图像码本 8 (158813 - 159836) ]  (1024 个 ID)</span>
<span class="na">[ 音频码本 1 (159837 - 160860) ]  (1024 个 ID)</span>
<span class="na">...</span>
<span class="na">[ 音频码本 8 (167005 - 168028) ]  (1024 个 ID)</span>
<span class="na">--- RVQ 码本区域结束 ---</span>
</code></pre></div>

<p>通过这种方式，一张 <code>16x16</code> 的 patch grid（共 256 个 patch），如果每个 patch 用 8 个 RVQ token 表示，那么这张图就被转换成 <code>256 * 8 = 2048</code> 个 token ID 序列，可以直接送入 Transformer。</p>
<h2 id="85">8.5 时间/空间位置编码与对齐标注</h2>
<p>Transformer 的位置编码（如 RoPE）天然地处理了序列中 token 的相对顺序。这对于文本和离散化后的其他模态来说是隐式的时空对齐。</p>
<ul>
<li><strong>空间对齐（图像/视频帧）</strong>：将图像 patch 或视频 tubelet 按光栅扫描顺序（raster-scan order）展平，其空间邻近关系就由序列中的相对位置隐式表达。</li>
<li><strong>时间对齐（音频/视频）</strong>：音频帧和视频按时间顺序排列，其时序关系也由序列位置隐式表达。</li>
</ul>
<p>对于需要更精确控制的场景，可以引入<strong>显式时间戳 token</strong>。例如，可以预留一些 token ID 或设计一种格式来表示绝对或相对时间，如 <code>&lt;time=15.2s&gt;</code>，但这会显著增加词表和序列的复杂性。在预训练的早期阶段，我们主要依赖隐式对齐。</p>
<h2 id="86">8.6 长上下文对齐与分块拼接策略</h2>
<p>模型上下文长度（如 8K 或 32K token）是有限的，但视频、音频或书籍可能非常长。处理长上下文的核心策略是<strong>分块（Chunking）</strong>。</p>
<ol>
<li><strong>固定长度分块</strong>：将长序列切分为固定 token 数量的块（chunk），例如每个块 8192 token。</li>
<li><strong>语义分块</strong>：根据视频的镜头切换、音频的静音段落或文本的章节来切分，更符合内容结构。</li>
<li><strong>重叠分块</strong>：为了让模型学习到块与块之间的连续性，相邻块之间可以有一定比例的重叠（overlap）。</li>
</ol>
<p>在训练时，每个块被视一个独立的样本。模型需要学习到，即使没有看到完整的上下文，也要能基于当前块的信息进行预测。</p>
<h2 id="87-packing">8.7 样本串联与 Packing 规范</h2>
<p>为了最大化 GPU 利用率，避免因处理大量短序列而浪费在 padding 上的计算，我们采用<strong>样本打包（Packing）</strong>策略。即将多个（通常是较短的）样本拼接成一个接近模型最大上下文长度的长序列。</p>
<p>一个打包后的多模态样本示例如下（ASCII 图）：</p>
<div class="codehilite"><pre><span></span><code><span class="o">&lt;|</span><span class="n">endoftext</span><span class="o">|&gt;</span><span class="w"> </span><span class="o">&lt;|</span><span class="n">im_start</span><span class="o">|&gt;</span><span class="k">user</span>
<span class="n">What</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="nc">image</span><span class="w"> </span><span class="n">show</span><span class="vm">?</span><span class="o">&lt;</span><span class="n">img</span><span class="o">&gt;[</span><span class="n">IMG_1</span><span class="o">]</span><span class="p">...</span><span class="o">[</span><span class="n">IMG_2048</span><span class="o">]&lt;/</span><span class="n">img</span><span class="o">&gt;&lt;|</span><span class="n">im_end</span><span class="o">|&gt;</span>
<span class="o">&lt;|</span><span class="n">im_start</span><span class="o">|&gt;</span><span class="n">assistant</span>
<span class="n">This</span><span class="w"> </span><span class="nc">image</span><span class="w"> </span><span class="n">shows</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">cat</span><span class="w"> </span><span class="n">sleeping</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">sofa</span><span class="p">.</span><span class="o">&lt;|</span><span class="n">endoftext</span><span class="o">|&gt;</span>
<span class="o">&lt;|</span><span class="n">endoftext</span><span class="o">|&gt;</span><span class="w"> </span><span class="o">&lt;</span><span class="n">aud</span><span class="o">&gt;[</span><span class="n">AUD_1</span><span class="o">]</span><span class="p">...</span><span class="o">[</span><span class="n">AUD_3000</span><span class="o">]&lt;/</span><span class="n">aud</span><span class="o">&gt;</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">audio</span><span class="w"> </span><span class="n">clip</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">weather</span><span class="w"> </span><span class="n">forecast</span><span class="p">.</span><span class="o">&lt;|</span><span class="n">endoftext</span><span class="o">|&gt;</span>
</code></pre></div>

<ul>
<li><code>[CONTEXT_LENGTH]</code></li>
<li><code>|&lt;- Sample 1 (Image QA) -&gt;|&lt;-- Sample 2 (Audio Caption) --&gt;| ... |</code></li>
</ul>
<p>关键点：</p>
<ul>
<li>使用 <code>&lt;|endoftext|&gt;</code> 作为样本间的分隔符。</li>
<li>在计算损失函数（Loss）时，需要一个 attention mask 确保一个样本内的 token 不会 "看到"（attend to）另一个样本的 token。即，在样本边界处 attention score 被置为 <code>-inf</code>。</li>
<li>这种方式极大地提高了训练吞吐量，是大规模预训练的标准实践。</li>
</ul>
<h2 id="88">8.8 词表版本化与兼容性</h2>
<p>Tokenizer 和词表是模型架构的基石，一旦确定并开始大规模训练，任何改动都会带来巨大的成本。</p>
<ul>
<li><strong>严格版本化</strong>：对 tokenizer 的配置文件、词表文件、特殊符号列表、RVQ 码本等进行严格的版本控制（如 Git LFS）。</li>
<li><strong>前向兼容设计</strong>：在初期设计时，可以预留一些未使用的特殊符号或 ID 区间，以备未来功能扩展之需，避免破坏性变更。</li>
<li><strong>变更影响</strong>：更改词表意味着模型的输入嵌入层（input embedding）和输出投影层（output projection/LM head）的权重矩阵尺寸需要改变。这通常需要重新训练或进行复杂的权重迁移，是项目中的重大决策。</li>
</ul>
<p><strong>经验法则</strong>：在项 P0 阶段结束后，应<strong>冻结（Freeze）</strong>词表和 tokenizer 的核心设计，后续只进行非破坏性的微调。</p>
<h2 id="89">8.9 本章小结</h2>
<p>本章详细阐述了如何构建一个能够统一处理文本、图像、音频和视频的多模态 tokenizer。我们从一个成熟的文本 tokenizer（Qwen）出发，通过增加特殊符号来赋予其结构化语义。核心创新在于使用 <strong>Encoder + RVQ</strong> 的两阶段方法，将所有非文本模态的连续数据高效地离散化为 token ID 序列，并将其码本无缝整合进一个统一的大词表中。我们还讨论了处理长上下文的<strong>分块</strong>策略、提升训练效率的<strong>样本打包</strong>技术，并强调了<strong>词表版本化</strong>在工程实践中的极端重要性。这个统一的离散化表示，是实现一个端到端多模态自回归大模型的技术前提。</p>
<h2 id="810-gotchas">8.10 常见陷阱与错误 (Gotchas)</h2>
<ol>
<li>
<p><strong>词表规模失控</strong>：过度追求高保真度，使用过多的 RVQ 码本或过大的码本尺寸，会导致词表急剧膨胀。这不仅增大了模型 Embedding 和 LM Head 的体积（显存占用），还可能因为数据稀疏而导致码本训练不足。</p>
<ul>
<li><strong>调试技巧</strong>：监控 RVQ 码本的利用率（codebook usage）。如果大量码字从未或很少被使用，说明码本过大或训练存在问题。</li>
</ul>
</li>
<li>
<p><strong>特殊符号冲突或滥用</strong>：在 tokenizer 中添加的特殊符号与原始 BPE 算法可能产生的 token 发生冲突，或者在数据预处理中错误地使用了这些符号，导致模型无法正确理解序列结构。</p>
<ul>
<li><strong>调试技巧</strong>：确保所有特殊符号都被设置为 "never_split"，并在预处理管道中进行单元测试，验证一个包含所有特殊符号的样本是否能被正确地 tokenize 和 de-tokenize。</li>
</ul>
</li>
<li>
<p><strong>忘记调整模型嵌入层尺寸</strong>：当扩展词表后，必须相应地调整模型中 <code>Embedding</code> 层和 <code>LM Head</code> 层的权重矩阵大小。忘记这一步会导致尺寸不匹配的运行时错误（runtime error）。</p>
<ul>
<li><strong>调试技巧</strong>：在加载 checkpoint 和模型定义时，加入严格的尺寸断言（assertion），确保词表大小与权重矩阵的第一维度完全匹配。</li>
</ul>
</li>
<li>
<p><strong>Packing 时的 Attention Mask 错误</strong>：在实现样本打包时，attention mask 的逻辑非常容易出错。如果 mask 不正确，会导致样本间信息泄露，模型会学到“抄近道”的捷径（例如，直接复制下一个样本的开头作为当前样本的结尾），使得 loss 虚假地降低，但模型实际能力很差。</p>
<ul>
<li><strong>调试技巧</strong>：对 attention mask 进行可视化抽查。构造一个包含多个短样本的 packed sequence，打印出 mask 矩阵，确保样本边界处是严格隔离的（即一个样本的 token 无法 attend to 另一个样本的 token）。</li>
</ul>
</li>
<li>
<p><strong>RVQ 码本坍缩 (Codebook Collapse)</strong>：在训练 VQ-VAE 或 Encodec 模型时，由于初始化或学习率不当，可能导致量化器只使用码本中的少数几个码字。这会严重损害离散化后的表示能。</p>
<ul>
<li><strong>调试技巧</strong>：持续监控每个码本中码字的 perplexity 和使用频率分布。健康的码本应该有较高的 perplexity 和相对均匀的使用分布。如果熵值很低，说明发生了坍缩。</li>
</ul>
</li>
</ol>
            </article>
            
            <nav class="page-nav"><a href="chapter7.html" class="nav-link prev">← 第 7 章 — 图像数据：采集、质量打分与离散化</a><a href="chapter9.html" class="nav-link next">模型结构与超参数（1B/10B） →</a></nav>
        </main>
    </div>
</body>
</html>