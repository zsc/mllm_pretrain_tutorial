# Tokenizer 与词表：多模扩词、特殊符与对齐

## 8.1 开篇与学习目标

本章是连接数据与模型的关键桥梁。在前几章中，我们已经将各种模态的数据（文本、音频、视频、图像）处理成了标准化的格式，但它们仍然是异构的。为了让一个统一的自回归 Transformer 模型能够理解和生成这些数据，我们必须将它们转换成一种通用的语言——离散的 token 序列。本章的目标是设计并实现一个多模态 tokenizer 和一个统一的词汇表，它能够无缝地表示所有模态的信息。

学完本章，您将能够：
*   理解为何以及如何在一个成熟的文本 tokenizer 基础上扩展多模态能力。
*   设计一套用于模态切换、分割和对齐的特殊符号系统。
*   掌握利用 **RVQ** (Residual Vector Quantization) 将连续特征（如音频、视频）离散化并整合进统词表的核心技术。
*   为长序列数据设计分块与拼接策略，并实现高效的样本打包（Packing）。
*   认识到词表版本管理的重要性及其对整个项目生命周ടിയ的影响。

## 8.2 文本沿用 Qwen tokenizer 的多模扩展

对于一个以中英文为核心的多模态模型，从零开始训练一个文本 tokenizer 并非明智之举。成熟的开源 tokenizer（如 Qwen、LLaMA 等使用的 BPE tokenizer）已经在海量文本上进行了优化，具备高效、覆盖广、语义分组合理的优点。我们的策略是**扩展（Extend）而非替换（Replace）**。

我们选择 **Qwen tokenizer** 作为基础，主要基于以下几点：
1.  **中英双语优化**：Qwen 的 tokenizer 对中英文语料都有很好的覆盖，符合我们数据配方中 90% 中英文的目标。
2.  **词表规模适中**：约 15 万的词表大小在表达能力和模型嵌入层大小之间取得了良好平衡。
3.  **社区生态成熟**：相关的预处脚本和社区支持较为完善，便于直接集成。

扩展的方式是在其现有词表的基础上，预留出新的 token ID 空间，用于后续添加特殊符号和非文本模态的离散码本。

## 8.3 模态特殊符与段标记

为了让模型在处理长序列时能够区分不同模态的数据、理解其结构，我们需要引入一套结构化的特殊符号（Special Tokens）。这些符号是模型的“语法标记”，指导其如何解析输入和生成输出。

| 特殊符         | 功能描述                                                     | 示例                                                |
| :------------- | :----------------------------------------------------------- | :-------------------------------------------------- |
| `<img>`        | 标志图像内容的开始                                           | `<img> [IMG_1] [IMG_2] ... </img>`                  |
| `</img>`       | 标志图像内容的结束                                           |                                                     |
| `<aud>`        | 标志音频内容的开始                                           | `<aud> [AUD_1] [AUD_2] ... </aud>`                  |
| `</aud>`       | 标志音频内容的结束                                           |                                                     |
| `<vid>`        | 标志视频内容的开始                                           | `<vid> [VID_1] [VID_2] ... </vid>`                  |
| `</vid>`       | 标志视频内容的结束                                           |                                                     |
| `<|im_start|>` | 对话或指令的起始标记                                         | `<|im_start|>user\n你好<|im_end|>`                 |
| `<|im_end|>`   | 对话或指令的结束标记                                         |                                                     |
| `<|endoftext|>`| 文档或样本的结束标记，用于样本打包（Packing）                | `... 一段文本 ...<|endoftext|>`                      |
| `<|sep|>`      | 通用分隔符，用于分隔不同语义块，如图像和其描述文本           | `<img>...</img> <|sep|> 一只猫的照片`                  |

这些特殊符号需要被添加到 tokenizer 的词表中，并赋予独一无二的 token ID。在训练时，模型会学习到这些符号的语义功能。

## 8.4 连续特征编码器 + RVQ 的码本并入统一词表

这是多模态 tokenizer 的核心。图像、音频、视频本质上是连续的高维信号。我们的统一离散化策略分为两步：
1.  **编码（Encode）**：使用一个预训练的、模态专用的编码器（如 ViT-VAE、Encodec）将原始数据块（如图像 patch、音频帧）压缩成低维的连续特征向量（latent vectors）。
2.  **量化（Quantize）**：使用 **RVQ (Residual Vector Quantization)** 将这些连续特征向量映射为离散的 token ID 序列。

**RVQ 工作原理简介：**
与 VQ-VAE 使用单个码（codebook）不同，RVQ 使用多个（例如 `N_q = 4` 或 `8`）码本。对于一个特征向量 `z`，RVQ 会逐步对其进行量化：
1.  在第一个码本 `C_1` 中找到最近的码字 `e_1`。
2.  计算残差 `r_1 = z - e_1`。
3.  在第二个码本 `C_2` 中为残差 `r_1` 找到最近的码字 `e_2`。
4.  计算新的残差 `r_2 = r_1 - e_2`。
5.  ... 以此类推，直到经过所有 `N_q` 个码本。

最终，原始向量 `z` 被近似表示为 `N_q` 个码字之和：`z ≈ e_1 + e_2 + ... + e_{N_q}`。而它的离散表示就是这 `N_q` 个码字对应的索引 `(idx_1, idx_2, ..., idx_{N_q})`。

**整合进统一词表：**
我们将每个 RVQ 码本视为一个独立的“词汇集”。假设每个码本大小为 1024，我们有 8 个码本用于图像，8 个用于音频。我们可以在 Qwen 的词表之后，为这些码本保留连续的 ID 区块。

```
[ ... 原始 Qwen 文本词表 (0 - 151642) ... ]
[ ... 特殊符号 (151643 - 151700) ... ]
--- RVQ 码本区域始 ---
[ 图像码本 1 (151701 - 152724) ]  (1024 个 ID)
[ 图像码本 2 (152725 - 153748) ]  (1024 个 ID)
...
[ 图像码本 8 (158813 - 159836) ]  (1024 个 ID)
[ 音频码本 1 (159837 - 160860) ]  (1024 个 ID)
...
[ 音频码本 8 (167005 - 168028) ]  (1024 个 ID)
--- RVQ 码本区域结束 ---
```
通过这种方式，一张 `16x16` 的 patch grid（共 256 个 patch），如果每个 patch 用 8 个 RVQ token 表示，那么这张图就被转换成 `256 * 8 = 2048` 个 token ID 序列，可以直接送入 Transformer。

## 8.5 时间/空间位置编码与对齐标注

Transformer 的位置编码（如 RoPE）天然地处理了序列中 token 的相对顺序。这对于文本和离散化后的其他模态来说是隐式的时空对齐。
*   **空间对齐（图像/视频帧）**：将图像 patch 或视频 tubelet 按光栅扫描顺序（raster-scan order）展平，其空间邻近关系就由序列中的相对位置隐式表达。
*   **时间对齐（音频/视频）**：音频帧和视频按时间顺序排列，其时序关系也由序列位置隐式表达。

对于需要更精确控制的场景，可以引入**显式时间戳 token**。例如，可以预留一些 token ID 或设计一种格式来表示绝对或相对时间，如 `<time=15.2s>`，但这会显著增加词表和序列的复杂性。在预训练的早期阶段，我们主要依赖隐式对齐。

## 8.6 长上下文对齐与分块拼接策略

模型上下文长度（如 8K 或 32K token）是有限的，但视频、音频或书籍可能非常长。处理长上下文的核心策略是**分块（Chunking）**。
1.  **固定长度分块**：将长序列切分为固定 token 数量的块（chunk），例如每个块 8192 token。
2.  **语义分块**：根据视频的镜头切换、音频的静音段落或文本的章节来切分，更符合内容结构。
3.  **重叠分块**：为了让模型学习到块与块之间的连续性，相邻块之间可以有一定比例的重叠（overlap）。

在训练时，每个块被视一个独立的样本。模型需要学习到，即使没有看到完整的上下文，也要能基于当前块的信息进行预测。

## 8.7 样本串联与 Packing 规范

为了最大化 GPU 利用率，避免因处理大量短序列而浪费在 padding 上的计算，我们采用**样本打包（Packing）**策略。即将多个（通常是较短的）样本拼接成一个接近模型最大上下文长度的长序列。

一个打包后的多模态样本示例如下（ASCII 图）：
```
<|endoftext|> <|im_start|>user
What does the image show?<img>[IMG_1]...[IMG_2048]</img><|im_end|>
<|im_start|>assistant
This image shows a cat sleeping on a sofa.<|endoftext|>
<|endoftext|> <aud>[AUD_1]...[AUD_3000]</aud> This is an audio clip of a weather forecast.<|endoftext|>
```
*   `[CONTEXT_LENGTH]`
*   `|<- Sample 1 (Image QA) ->|<-- Sample 2 (Audio Caption) -->| ... |`

关键点：
*   使用 `<|endoftext|>` 作为样本间的分隔符。
*   在计算损失函数（Loss）时，需要一个 attention mask 确保一个样本内的 token 不会 "看到"（attend to）另一个样本的 token。即，在样本边界处 attention score 被置为 `-inf`。
*   这种方式极大地提高了训练吞吐量，是大规模预训练的标准实践。

## 8.8 词表版本化与兼容性

Tokenizer 和词表是模型架构的基石，一旦确定并开始大规模训练，任何改动都会带来巨大的成本。
*   **严格版本化**：对 tokenizer 的配置文件、词表文件、特殊符号列表、RVQ 码本等进行严格的版本控制（如 Git LFS）。
*   **前向兼容设计**：在初期设计时，可以预留一些未使用的特殊符号或 ID 区间，以备未来功能扩展之需，避免破坏性变更。
*   **变更影响**：更改词表意味着模型的输入嵌入层（input embedding）和输出投影层（output projection/LM head）的权重矩阵尺寸需要改变。这通常需要重新训练或进行复杂的权重迁移，是项目中的重大决策。

**经验法则**：在项 P0 阶段结束后，应**冻结（Freeze）**词表和 tokenizer 的核心设计，后续只进行非破坏性的微调。

## 8.9 本章小结

本章详细阐述了如何构建一个能够统一处理文本、图像、音频和视频的多模态 tokenizer。我们从一个成熟的文本 tokenizer（Qwen）出发，通过增加特殊符号来赋予其结构化语义。核心创新在于使用 **Encoder + RVQ** 的两阶段方法，将所有非文本模态的连续数据高效地离散化为 token ID 序列，并将其码本无缝整合进一个统一的大词表中。我们还讨论了处理长上下文的**分块**策略、提升训练效率的**样本打包**技术，并强调了**词表版本化**在工程实践中的极端重要性。这个统一的离散化表示，是实现一个端到端多模态自回归大模型的技术前提。

## 8.10 常见陷阱与错误 (Gotchas)

1.  **词表规模失控**：过度追求高保真度，使用过多的 RVQ 码本或过大的码本尺寸，会导致词表急剧膨胀。这不仅增大了模型 Embedding 和 LM Head 的体积（显存占用），还可能因为数据稀疏而导致码本训练不足。
    *   **调试技巧**：监控 RVQ 码本的利用率（codebook usage）。如果大量码字从未或很少被使用，说明码本过大或训练存在问题。

2.  **特殊符号冲突或滥用**：在 tokenizer 中添加的特殊符号与原始 BPE 算法可能产生的 token 发生冲突，或者在数据预处理中错误地使用了这些符号，导致模型无法正确理解序列结构。
    *   **调试技巧**：确保所有特殊符号都被设置为 "never_split"，并在预处理管道中进行单元测试，验证一个包含所有特殊符号的样本是否能被正确地 tokenize 和 de-tokenize。

3.  **忘记调整模型嵌入层尺寸**：当扩展词表后，必须相应地调整模型中 `Embedding` 层和 `LM Head` 层的权重矩阵大小。忘记这一步会导致尺寸不匹配的运行时错误（runtime error）。
    *   **调试技巧**：在加载 checkpoint 和模型定义时，加入严格的尺寸断言（assertion），确保词表大小与权重矩阵的第一维度完全匹配。

4.  **Packing 时的 Attention Mask 错误**：在实现样本打包时，attention mask 的逻辑非常容易出错。如果 mask 不正确，会导致样本间信息泄露，模型会学到“抄近道”的捷径（例如，直接复制下一个样本的开头作为当前样本的结尾），使得 loss 虚假地降低，但模型实际能力很差。
    *   **调试技巧**：对 attention mask 进行可视化抽查。构造一个包含多个短样本的 packed sequence，打印出 mask 矩阵，确保样本边界处是严格隔离的（即一个样本的 token 无法 attend to 另一个样本的 token）。

5.  **RVQ 码本坍缩 (Codebook Collapse)**：在训练 VQ-VAE 或 Encodec 模型时，由于初始化或学习率不当，可能导致量化器只使用码本中的少数几个码字。这会严重损害离散化后的表示能。
    *   **调试技巧**：持续监控每个码本中码字的 perplexity 和使用频率分布。健康的码本应该有较高的 perplexity 和相对均匀的使用分布。如果熵值很低，说明发生了坍缩。
